{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('label.csv')\n",
    "\n",
    "image_directory = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edges(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges.flatten()\n",
    "\n",
    "# Function to extract ORB features\n",
    "def extract_orb_features(image, max_features=128):\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] > max_features:\n",
    "            descriptors = descriptors[:max_features, :]\n",
    "        elif descriptors.shape[0] < max_features:\n",
    "            padding = np.zeros((max_features - descriptors.shape[0], descriptors.shape[1]))\n",
    "            descriptors = np.vstack((descriptors, padding))\n",
    "        return descriptors.flatten()\n",
    "    else:\n",
    "        return np.zeros(max_features * 32)\n",
    "\n",
    "# Function to extract HOG features\n",
    "def extract_hog_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = hog(gray_image, pixels_per_cell=(24, 24), block_norm='L2-Hys')\n",
    "    return features\n",
    "\n",
    "# Function to extract LBP features\n",
    "def extract_lbp_features(image, radii=[1, 2, 3], n_points=8, method='uniform'):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_features = []\n",
    "    \n",
    "    for radius in radii:\n",
    "        lbp = local_binary_pattern(gray_image, n_points, radius, method=method)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        lbp_features.extend(hist)\n",
    "    \n",
    "    return np.array(lbp_features) \n",
    "\n",
    "# Function to extract color histogram features\n",
    "def extract_color_histogram(image):\n",
    "    # Load the image\n",
    "    \n",
    "    # Compute the histogram for each color channel (B, G, R)\n",
    "    hist_b = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([image], [1], None, [256], [0, 256])\n",
    "    hist_r = cv2.calcHist([image], [2], None, [256], [0, 256])\n",
    "    \n",
    "    # Normalize the histograms\n",
    "    hist_b = cv2.normalize(hist_b, hist_b).flatten()\n",
    "    hist_g = cv2.normalize(hist_g, hist_g).flatten()\n",
    "    hist_r = cv2.normalize(hist_r, hist_r).flatten()\n",
    "\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate([hist_b, hist_g, hist_r])\n",
    "\n",
    "    # print(hist_features.shape)\n",
    "\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "\n",
    "def extract_gftt_features(image, max_corners=100, quality_level=0.01, min_distance=10):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    corners = cv2.goodFeaturesToTrack(gray_image, maxCorners=max_corners, qualityLevel=quality_level, minDistance=min_distance)\n",
    "    if corners is not None:\n",
    "        corners = corners.flatten()\n",
    "    else:\n",
    "        corners = np.zeros(max_corners * 2)  # Assuming 2 coordinates per corner\n",
    "    return corners\n",
    "\n",
    "def extract_harris_features(image, block_size=2, ksize=3, k=0.04):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    harris_corners = cv2.cornerHarris(gray_image, blockSize=block_size, ksize=ksize, k=k)\n",
    "    harris_corners = cv2.normalize(harris_corners, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    return harris_corners.flatten()\n",
    "\n",
    "def extract_gabor_features(image, ksize=31, sigma=4.0, theta=1.0, lambd=10.0, gamma=0.5, psi=0):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gabor_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n",
    "    filtered_image = cv2.filter2D(gray_image, cv2.CV_8UC3, gabor_kernel)\n",
    "    return filtered_image.flatten()\n",
    "\n",
    "def extract_sobel_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    grad_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    grad_magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "    grad_magnitude = cv2.normalize(grad_magnitude, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    return grad_magnitude.flatten()\n",
    "\n",
    "\n",
    "# Combine all features into a single feature vector\n",
    "def extract_combined_features(image, pca_model):\n",
    "    edges = extract_edges(image)\n",
    "    if edges is not None:\n",
    "        edges = pca_model.transform([edges])[0]  # Apply PCA\n",
    "\n",
    "    orb_features = extract_orb_features(image)\n",
    "    hog_features = extract_hog_features(image)\n",
    "    lbp_features = extract_lbp_features(image)\n",
    "    color_histogram = extract_color_histogram(image)\n",
    "    gftt_features = extract_gftt_features(image)\n",
    "\n",
    "    harris_features = extract_harris_features(image)\n",
    "    if harris_features is not None:\n",
    "        harris_features = pca_model.transform([harris_features])[0]  # Apply PCA\n",
    "\n",
    "    gabor_features = extract_gabor_features(image)\n",
    "    if gabor_features is not None:\n",
    "        gabor_features = pca_model.transform([gabor_features])[0]  # Apply PCA\n",
    "\n",
    "    sobel_features = extract_sobel_features(image)\n",
    "    if sobel_features is not None:\n",
    "        sobel_features = pca_model.transform([sobel_features])[0]  # Apply PCA\n",
    "\n",
    "\n",
    "    # print(f\"edges shape: {edges.shape}, orb_features shape: {orb_features.shape}, hog_features shape: {hog_features.shape}, lbp_features shape: {lbp_features.shape}, color_histogram shape: {color_histogram.shape}\")\n",
    "\n",
    "    combined_features = np.concatenate((edges, orb_features, hog_features, lbp_features, color_histogram, gftt_features, harris_features, gabor_features, sobel_features))\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/Image_1.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Resize the image if needed\n",
    "resized_image = cv2.resize(image, (250, 200))\n",
    "\n",
    "# # pca = PCA(n_components=100)\n",
    "# # Extract combined features\n",
    "# combined_features = extract_combined_features(resized_image)\n",
    "\n",
    "\n",
    "# gftt_features = extract_gftt_features(resized_image)\n",
    "# harris_features = extract_harris_features(resized_image)\n",
    "# gabor_features = extract_gabor_features(resized_image)\n",
    "# sobel_features = extract_sobel_features(resized_image)\n",
    "\n",
    "# # Printing the shapes of each feature\n",
    "# print(f\"gftt features shape: {gftt_features.shape}\")\n",
    "# print(f\"harris features shape: {harris_features.shape}\")\n",
    "# print(f\"gabor features shape: {gabor_features.shape}\")\n",
    "# print(f\"sobel features shape: {sobel_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = []\n",
    "\n",
    "# First pass: Collect edges to fit PCA\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(image_directory, row['filename'])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Ensure the image is loaded correctly\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Resize the image if needed\n",
    "    resized_image = cv2.resize(image, (250, 200))\n",
    "    \n",
    "    # Extract edges\n",
    "    edges = extract_edges(resized_image)\n",
    "    print(image_path, edges.shape, end='\\r')\n",
    "\n",
    "    if edges is not None:\n",
    "        all_edges.append(edges)\n",
    "\n",
    "# Fit PCA on the collected edge features\n",
    "all_edges = np.array(all_edges)\n",
    "\n",
    "# Apply PCA and store the transformed features\n",
    "pca = PCA(n_components=100)\n",
    "all_edges_pca = pca.fit_transform(all_edges)  # This line transforms the features and stores them\n",
    "\n",
    "# Print the shape of the reduced-dimension data\n",
    "print(all_edges_pca.shape)\n",
    "\n",
    "print(f\"PCA model fitted. {all_edges_pca.shape[0]} samples with {all_edges_pca.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_harris_features = []\n",
    "\n",
    "# First pass: Collect Harris corner features to fit PCA\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(image_directory, row['filename'])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Ensure the image is loaded correctly\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Resize the image if needed\n",
    "    resized_image = cv2.resize(image, (250, 200))\n",
    "    \n",
    "    # Extract Harris corner features\n",
    "    harris_features = extract_harris_features(resized_image)\n",
    "    print(image_path, harris_features.shape, end='\\r')\n",
    "\n",
    "    if harris_features is not None:\n",
    "        all_harris_features.append(harris_features)\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_harris_features = np.array(all_harris_features)\n",
    "\n",
    "# Fit PCA on the collected Harris corner features and apply transformation\n",
    "pca_harris = PCA(n_components=100)  # Choose appropriate number of components\n",
    "harris_features_pca = pca_harris.fit_transform(all_harris_features)  # Store the transformed features\n",
    "\n",
    "# Print the shape of the reduced-dimension data\n",
    "print(harris_features_pca.shape)\n",
    "\n",
    "print(f\"PCA model fitted on Harris features. {harris_features_pca.shape[0]} samples with {harris_features_pca.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gabor_features = []\n",
    "\n",
    "# First pass: Collect Gabor features to fit PCA\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(image_directory, row['filename'])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Ensure the image is loaded correctly\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Resize the image if needed\n",
    "    resized_image = cv2.resize(image, (250, 200))\n",
    "    \n",
    "    # Extract Gabor features\n",
    "    gabor_features = extract_gabor_features(resized_image)\n",
    "    print(image_path, gabor_features.shape, end='\\r')\n",
    "\n",
    "    if gabor_features is not None:\n",
    "        all_gabor_features.append(gabor_features)\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_gabor_features = np.array(all_gabor_features)\n",
    "\n",
    "# Fit PCA on the collected Gabor features and apply transformation\n",
    "pca_gabor = PCA(n_components=100)  # Choose appropriate number of components\n",
    "gabor_features_pca = pca_gabor.fit_transform(all_gabor_features)  # Store the transformed features\n",
    "\n",
    "# Print the shape of the reduced-dimension data\n",
    "print(gabor_features_pca.shape)\n",
    "\n",
    "print(f\"PCA model fitted on Gabor features. {gabor_features_pca.shape[0]} samples with {gabor_features_pca.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sobel_features = []\n",
    "\n",
    "# First pass: Collect Sobel features to fit PCA\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_path = os.path.join(image_directory, row['filename'])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Ensure the image is loaded correctly\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    # Resize the image if needed\n",
    "    resized_image = cv2.resize(image, (250, 200))\n",
    "    \n",
    "    # Extract Sobel features\n",
    "    sobel_features = extract_sobel_features(resized_image)\n",
    "    print(image_path, sobel_features.shape, end='\\r')\n",
    "\n",
    "    if sobel_features is not None:\n",
    "        all_sobel_features.append(sobel_features)\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "all_sobel_features = np.array(all_sobel_features)\n",
    "\n",
    "# Fit PCA on the collected Sobel features and apply transformation\n",
    "pca_sobel = PCA(n_components=100)  # Choose appropriate number of components\n",
    "sobel_features_pca = pca_sobel.fit_transform(all_sobel_features)  # Store the transformed features\n",
    "\n",
    "# Print the shape of the reduced-dimension data\n",
    "print(sobel_features_pca.shape)\n",
    "\n",
    "print(f\"PCA model fitted on Sobel features. {sobel_features_pca.shape[0]} samples with {sobel_features_pca.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_written = False\n",
    "\n",
    "# with open('extracted_features_pca.csv', 'w') as csvfile:\n",
    "#     for index, row in labels_df.iterrows():\n",
    "#         image_path = os.path.join(image_directory, row['filename'])\n",
    "#         image = cv2.imread(image_path)\n",
    "\n",
    "#         # Ensure the image is loaded correctly\n",
    "#         if image is None:\n",
    "#             continue\n",
    "        \n",
    "#         # Resize the image if needed\n",
    "#         resized_image = cv2.resize(image, (250, 200))\n",
    "        \n",
    "#         # Extract combined features\n",
    "#         combined_features = extract_combined_features(resized_image, pca)\n",
    "#         print(image_path, combined_features.shape, end='\\r')\n",
    "\n",
    "#         # Normalize features\n",
    "#         scaler = StandardScaler()\n",
    "#         X = scaler.fit_transform(combined_features)\n",
    "        \n",
    "#         # Convert features to a DataFrame row with label and filename\n",
    "#         combined_row = np.append(X, [row['label'], row['filename']])\n",
    "        \n",
    "#         # Convert to DataFrame\n",
    "#         combined_df = pd.DataFrame([combined_row])\n",
    "        \n",
    "#         # Write the row to the CSV, writing the header only once\n",
    "#         if not header_written:\n",
    "#             combined_df.to_csv(csvfile, header=['feature_' + str(i) for i in range(len(combined_features))] + ['label', 'filename'], index=False, mode='a')\n",
    "#             header_written = True\n",
    "#         else:\n",
    "#             combined_df.to_csv(csvfile, header=False, index=False, mode='a')\n",
    "\n",
    "# print(\"Feature extraction completed and saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(row_tuple):\n",
    "    index, row = row_tuple\n",
    "    image_path = os.path.join(image_directory, row['filename'])\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    resized_image = cv2.resize(image, (250, 200))\n",
    "\n",
    "    # Extract combined features\n",
    "    combined_features = extract_combined_features(resized_image, pca)\n",
    "    print(image_path, combined_features.shape, end='\\r')\n",
    "\n",
    "    # Return features along with label and filename\n",
    "    return np.append(combined_features, [row['label'], row['filename']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # Directly pass the row tuples from labels_df.iterrows()\n",
    "    results = list(executor.map(process_image, labels_df.iterrows()))\n",
    "\n",
    "# Filter out None results (in case any image failed to load)\n",
    "results = [result for result in results if result is not None]\n",
    "features_list.extend(results)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_df.iloc[:, :-2] = scaler.fit_transform(features_df.iloc[:, :-2])\n",
    "\n",
    "# Write to CSV\n",
    "features_df.columns = ['feature_' + str(i) for i in range(features_df.shape[1] - 2)] + ['label', 'filename']\n",
    "features_df.to_csv('extracted_features_pca.csv', index=False)\n",
    "\n",
    "print(\"Feature extraction completed and saved to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
