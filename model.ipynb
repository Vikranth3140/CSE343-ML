{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features from CSV\n",
    "features_df = pd.read_csv('extracted_features_pca.csv')\n",
    "\n",
    "# Separate features, labels, and filenames\n",
    "X = features_df.drop(columns=['label', 'filename']).values\n",
    "y = LabelEncoder().fit_transform(features_df['label'].values)\n",
    "file_names = features_df['filename'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"max_features\":'sqrt',\n",
    "    \"max_depth\":30,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1\n",
    "\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(**best_rf_params)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "\n",
    "# Split importances back into the respective feature categories\n",
    "edges_importance = importances[:100]\n",
    "orb_importance = importances[100:100+4096]\n",
    "hog_importance = importances[100+4096:100+4096+3888]\n",
    "lbp_importance = importances[100+4096+3888:100+4096+3888+30]\n",
    "color_histogram_importance = importances[100+4096+3888+30:]\n",
    "\n",
    "# Sum the importances for each category\n",
    "category_importances = {\n",
    "    'edges': np.sum(edges_importance),\n",
    "    'orb_features': np.sum(orb_importance),\n",
    "    'hog_features': np.sum(hog_importance),\n",
    "    'lbp_features': np.sum(lbp_importance),\n",
    "    'color_histogram': np.sum(color_histogram_importance)\n",
    "}\n",
    "\n",
    "# Convert to pandas Series for easier viewing\n",
    "category_importances_series = pd.Series(category_importances)\n",
    "\n",
    "# Print the importances by category\n",
    "print(category_importances_series.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model_filename = 'trained_random_forest_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(rf, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
