{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy matplotlib tensorflow tensorflow pickle-mixin scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, N, layer_sizes, lr, activation, weight_init, epochs, batch_size):\n",
    "        self.N = N  # Number of layers\n",
    "        self.layer_sizes = layer_sizes  # List of neurons in each layer\n",
    "        self.lr = lr  # Learning rate\n",
    "        self.activation = activation  # Activation function\n",
    "        self.weight_init = weight_init  # Weight initialization method\n",
    "        self.epochs = epochs  # Number of epochs\n",
    "        self.batch_size = batch_size  # Batch size\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights, self.biases = self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        weights = []\n",
    "        biases = []\n",
    "\n",
    "        for i in range(self.N - 1):\n",
    "            if self.weight_init == \"xavier\":\n",
    "                weight = np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * np.sqrt(1 / self.layer_sizes[i])\n",
    "            elif self.weight_init == \"he\":\n",
    "                weight = np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * np.sqrt(2 / self.layer_sizes[i])\n",
    "            else:  # default random initialization\n",
    "                weight = np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * 0.01\n",
    "            bias = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "\n",
    "            weights.append(weight)\n",
    "            biases.append(bias)\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def activation_function(self, z):\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(0, z)\n",
    "        elif self.activation == \"tanh\":\n",
    "            return np.tanh(z)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    def activation_derivative(self, z):\n",
    "        if self.activation == \"relu\":\n",
    "            return np.where(z > 0, 1, 0)\n",
    "        elif self.activation == \"tanh\":\n",
    "            return 1 - np.tanh(z) ** 2\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            sig = self.activation_function(z)\n",
    "            return sig * (1 - sig)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        activations = [X]\n",
    "        zs = []\n",
    "\n",
    "        for i in range(self.N - 2):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            zs.append(z)\n",
    "            activation = self.activation_function(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # Output layer with softmax for probabilities\n",
    "        z = np.dot(activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        zs.append(z)\n",
    "        activation = self.softmax(z)\n",
    "        activations.append(activation)\n",
    "\n",
    "        return activations, zs\n",
    "\n",
    "    def backward(self, X, Y, activations, zs):\n",
    "        grads_w = [None] * (self.N - 1)\n",
    "        grads_b = [None] * (self.N - 1)\n",
    "\n",
    "        # Output layer error\n",
    "        delta = activations[-1] - Y  # Assuming Y is one-hot encoded\n",
    "        grads_w[-1] = np.dot(activations[-2].T, delta) / X.shape[0]\n",
    "        grads_b[-1] = np.sum(delta, axis=0, keepdims=True) / X.shape[0]\n",
    "\n",
    "        # Backpropagation through hidden layers\n",
    "        for i in range(self.N - 3, -1, -1):\n",
    "            delta = np.dot(delta, self.weights[i + 1].T) * self.activation_derivative(zs[i])\n",
    "            grads_w[i] = np.dot(activations[i].T, delta) / X.shape[0]\n",
    "            grads_b[i] = np.sum(delta, axis=0, keepdims=True) / X.shape[0]\n",
    "\n",
    "        return grads_w, grads_b\n",
    "\n",
    "    def update_parameters(self, grads_w, grads_b):\n",
    "        for i in range(self.N - 1):\n",
    "            self.weights[i] -= self.lr * grads_w[i]\n",
    "            self.biases[i] -= self.lr * grads_b[i]\n",
    "\n",
    "    def fit(self, X, Y, X_val=None, Y_val=None, early_stopping=False, patience=10):\n",
    "        epoch_loss = None  # Initialize the loss variable\n",
    "        best_val_loss = float('inf')  # Initialize best validation loss\n",
    "        wait = 0  # Initialize wait counter for early stopping\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            indices = np.arange(X.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            for start in range(0, X.shape[0], self.batch_size):\n",
    "                end = start + self.batch_size\n",
    "                batch_indices = indices[start:end]\n",
    "                X_batch, Y_batch = X[batch_indices], Y[batch_indices]\n",
    "\n",
    "                activations, zs = self.forward(X_batch)\n",
    "                grads_w, grads_b = self.backward(X_batch, Y_batch, activations, zs)\n",
    "                self.update_parameters(grads_w, grads_b)\n",
    "\n",
    "            # Calculate training loss for the current epoch\n",
    "            full_activations, _ = self.forward(X)\n",
    "            epoch_loss = -np.mean(np.sum(Y * np.log(full_activations[-1] + 1e-8), axis=1))\n",
    "\n",
    "            # Validation loss calculation\n",
    "            if X_val is not None and Y_val is not None:\n",
    "                val_predictions = self.predict_proba(X_val)\n",
    "                val_loss = -np.mean(np.sum(Y_val * np.log(val_predictions + 1e-8), axis=1))\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "                # Early stopping check\n",
    "                if early_stopping:\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        wait = 0  # Reset the wait counter\n",
    "                    else:\n",
    "                        wait += 1\n",
    "                        if wait >= patience:\n",
    "                            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                            break\n",
    "            else:\n",
    "                print(f\"Epoch {epoch + 1}/{self.epochs}, Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        return epoch_loss  # Return the calculated epoch loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return activations[-1]\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        labels = np.argmax(Y, axis=1)  # Assuming Y is one-hot encoded\n",
    "        accuracy = np.mean(predictions == labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ActivationFunctions:\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(z):\n",
    "        \"\"\"\n",
    "        Derivative of the sigmoid function.\n",
    "        \"\"\"\n",
    "        sig = ActivationFunctions.sigmoid(z)\n",
    "        return sig * (1 - sig)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(z):\n",
    "        \"\"\"\n",
    "        Tanh activation function.\n",
    "        \"\"\"\n",
    "        return np.tanh(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_derivative(z):\n",
    "        \"\"\"\n",
    "        Derivative of the tanh function.\n",
    "        \"\"\"\n",
    "        return 1 - np.tanh(z) ** 2\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        \"\"\"\n",
    "        ReLU activation function.\n",
    "        \"\"\"\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(z):\n",
    "        \"\"\"\n",
    "        Derivative of the ReLU function.\n",
    "        \"\"\"\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def leaky_relu(z, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Leaky ReLU activation function with a small slope for negative inputs.\n",
    "        \"\"\"\n",
    "        return np.where(z > 0, z, alpha * z)\n",
    "\n",
    "    @staticmethod\n",
    "    def leaky_relu_derivative(z, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Derivative of the Leaky ReLU function.\n",
    "        \"\"\"\n",
    "        return np.where(z > 0, 1, alpha)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(z):\n",
    "        \"\"\"\n",
    "        Softmax activation function for the output layer.\n",
    "        \"\"\"\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Stability improvement\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class WeightInitializer:\n",
    "    \n",
    "    @staticmethod\n",
    "    def zero_init(shape):\n",
    "        \"\"\"\n",
    "        Initializes weights to zero.\n",
    "        \"\"\"\n",
    "        return np.zeros(shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_init(shape, scale=0.01):\n",
    "        \"\"\"\n",
    "        Initializes weights randomly within a uniform distribution.\n",
    "        \"\"\"\n",
    "        return np.random.uniform(-scale, scale, shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normal_init(shape, scale=1.0):\n",
    "        \"\"\"\n",
    "        Initializes weights using a normal distribution with mean 0 and standard deviation scale.\n",
    "        \"\"\"\n",
    "        return np.random.normal(0, scale, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 08:50:39.910974: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 08:50:39.914753: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 08:50:39.922989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731228639.935360 1460595 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731228639.939129 1460595 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 08:50:39.954576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with activation: sigmoid and weight initialization: zero_init\n",
      "Epoch 1/100, Train Loss: 2.3025, Val Loss: 2.3021\n",
      "Epoch 2/100, Train Loss: 2.3040, Val Loss: 2.3049\n",
      "Epoch 3/100, Train Loss: 2.3054, Val Loss: 2.3063\n",
      "Epoch 4/100, Train Loss: 2.3035, Val Loss: 2.3050\n",
      "Epoch 5/100, Train Loss: 2.3024, Val Loss: 2.3038\n",
      "Epoch 6/100, Train Loss: 2.3020, Val Loss: 2.3033\n",
      "Epoch 7/100, Train Loss: 2.3027, Val Loss: 2.3042\n",
      "Epoch 8/100, Train Loss: 2.3023, Val Loss: 2.3032\n",
      "Epoch 9/100, Train Loss: 2.3037, Val Loss: 2.3042\n",
      "Epoch 10/100, Train Loss: 2.3032, Val Loss: 2.3028\n",
      "Epoch 11/100, Train Loss: 2.3018, Val Loss: 2.3023\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 1/100 - Train Loss: 2.301806188464979 - Val Loss: 2.302292349397229\n",
      "Epoch 1/100, Train Loss: 2.3040, Val Loss: 2.3028\n",
      "Epoch 2/100, Train Loss: 2.3022, Val Loss: 2.3031\n",
      "Epoch 3/100, Train Loss: 2.3019, Val Loss: 2.3033\n",
      "Epoch 4/100, Train Loss: 2.3027, Val Loss: 2.3028\n",
      "Epoch 5/100, Train Loss: 2.3017, Val Loss: 2.3025\n",
      "Epoch 6/100, Train Loss: 2.3024, Val Loss: 2.3033\n",
      "Epoch 7/100, Train Loss: 2.3020, Val Loss: 2.3023\n",
      "Epoch 8/100, Train Loss: 2.3021, Val Loss: 2.3028\n",
      "Epoch 9/100, Train Loss: 2.3020, Val Loss: 2.3040\n",
      "Epoch 10/100, Train Loss: 2.3018, Val Loss: 2.3031\n",
      "Epoch 11/100, Train Loss: 2.3038, Val Loss: 2.3060\n",
      "Epoch 12/100, Train Loss: 2.3030, Val Loss: 2.3028\n",
      "Epoch 13/100, Train Loss: 2.3016, Val Loss: 2.3016\n",
      "Epoch 14/100, Train Loss: 2.3026, Val Loss: 2.3044\n",
      "Epoch 15/100, Train Loss: 2.3015, Val Loss: 2.3024\n",
      "Epoch 16/100, Train Loss: 2.3021, Val Loss: 2.3027\n",
      "Epoch 17/100, Train Loss: 2.3020, Val Loss: 2.3025\n",
      "Epoch 18/100, Train Loss: 2.3011, Val Loss: 2.3020\n",
      "Epoch 19/100, Train Loss: 2.3014, Val Loss: 2.3026\n",
      "Epoch 20/100, Train Loss: 2.3016, Val Loss: 2.3026\n",
      "Epoch 21/100, Train Loss: 2.3017, Val Loss: 2.3032\n",
      "Epoch 22/100, Train Loss: 2.3021, Val Loss: 2.3024\n",
      "Epoch 23/100, Train Loss: 2.3011, Val Loss: 2.3020\n",
      "Early stopping triggered at epoch 23\n",
      "Epoch 2/100 - Train Loss: 2.301130407857535 - Val Loss: 2.302014687855775\n",
      "Epoch 1/100, Train Loss: 2.3014, Val Loss: 2.3027\n",
      "Epoch 2/100, Train Loss: 2.3010, Val Loss: 2.3019\n",
      "Epoch 3/100, Train Loss: 2.3006, Val Loss: 2.3016\n",
      "Epoch 4/100, Train Loss: 2.3002, Val Loss: 2.3012\n",
      "Epoch 5/100, Train Loss: 2.3000, Val Loss: 2.3011\n",
      "Epoch 6/100, Train Loss: 2.2987, Val Loss: 2.2996\n",
      "Epoch 7/100, Train Loss: 2.2970, Val Loss: 2.2984\n",
      "Epoch 8/100, Train Loss: 2.2939, Val Loss: 2.2950\n",
      "Epoch 9/100, Train Loss: 2.2888, Val Loss: 2.2899\n",
      "Epoch 10/100, Train Loss: 2.2791, Val Loss: 2.2810\n",
      "Epoch 11/100, Train Loss: 2.2566, Val Loss: 2.2576\n",
      "Epoch 12/100, Train Loss: 2.1818, Val Loss: 2.1845\n",
      "Epoch 13/100, Train Loss: 2.0147, Val Loss: 2.0193\n",
      "Epoch 14/100, Train Loss: 1.9242, Val Loss: 1.9262\n",
      "Epoch 15/100, Train Loss: 1.8486, Val Loss: 1.8477\n",
      "Epoch 16/100, Train Loss: 1.7833, Val Loss: 1.7789\n",
      "Epoch 17/100, Train Loss: 1.7388, Val Loss: 1.7313\n",
      "Epoch 18/100, Train Loss: 1.7057, Val Loss: 1.6966\n",
      "Epoch 19/100, Train Loss: 1.6773, Val Loss: 1.6682\n",
      "Epoch 20/100, Train Loss: 1.6512, Val Loss: 1.6420\n",
      "Epoch 21/100, Train Loss: 1.6281, Val Loss: 1.6187\n",
      "Epoch 22/100, Train Loss: 1.6067, Val Loss: 1.5980\n",
      "Epoch 23/100, Train Loss: 1.5887, Val Loss: 1.5808\n",
      "Epoch 24/100, Train Loss: 1.5787, Val Loss: 1.5697\n",
      "Epoch 25/100, Train Loss: 1.5509, Val Loss: 1.5431\n",
      "Epoch 26/100, Train Loss: 1.5302, Val Loss: 1.5221\n",
      "Epoch 27/100, Train Loss: 1.5104, Val Loss: 1.5024\n",
      "Epoch 28/100, Train Loss: 1.4886, Val Loss: 1.4803\n",
      "Epoch 29/100, Train Loss: 1.4652, Val Loss: 1.4586\n",
      "Epoch 30/100, Train Loss: 1.4427, Val Loss: 1.4351\n",
      "Epoch 31/100, Train Loss: 1.4127, Val Loss: 1.4060\n",
      "Epoch 32/100, Train Loss: 1.3863, Val Loss: 1.3794\n",
      "Epoch 33/100, Train Loss: 1.3402, Val Loss: 1.3324\n",
      "Epoch 34/100, Train Loss: 1.2860, Val Loss: 1.2801\n",
      "Epoch 35/100, Train Loss: 1.2152, Val Loss: 1.2077\n",
      "Epoch 36/100, Train Loss: 1.0768, Val Loss: 1.0651\n",
      "Epoch 37/100, Train Loss: 0.9192, Val Loss: 0.9083\n",
      "Epoch 38/100, Train Loss: 0.8209, Val Loss: 0.8109\n",
      "Epoch 39/100, Train Loss: 0.7673, Val Loss: 0.7580\n",
      "Epoch 40/100, Train Loss: 0.7306, Val Loss: 0.7220\n",
      "Epoch 41/100, Train Loss: 0.7001, Val Loss: 0.6928\n",
      "Epoch 42/100, Train Loss: 0.6724, Val Loss: 0.6674\n",
      "Epoch 43/100, Train Loss: 0.6503, Val Loss: 0.6469\n",
      "Epoch 44/100, Train Loss: 0.6263, Val Loss: 0.6232\n",
      "Epoch 45/100, Train Loss: 0.6011, Val Loss: 0.5980\n",
      "Epoch 46/100, Train Loss: 0.5827, Val Loss: 0.5829\n",
      "Epoch 47/100, Train Loss: 0.5533, Val Loss: 0.5519\n",
      "Epoch 48/100, Train Loss: 0.5154, Val Loss: 0.5149\n",
      "Epoch 49/100, Train Loss: 0.4786, Val Loss: 0.4755\n",
      "Epoch 50/100, Train Loss: 0.4350, Val Loss: 0.4346\n",
      "Epoch 51/100, Train Loss: 0.4056, Val Loss: 0.4034\n",
      "Epoch 52/100, Train Loss: 0.3716, Val Loss: 0.3710\n",
      "Epoch 53/100, Train Loss: 0.3533, Val Loss: 0.3538\n",
      "Epoch 54/100, Train Loss: 0.3345, Val Loss: 0.3362\n",
      "Epoch 55/100, Train Loss: 0.3191, Val Loss: 0.3220\n",
      "Epoch 56/100, Train Loss: 0.3043, Val Loss: 0.3053\n",
      "Epoch 57/100, Train Loss: 0.2987, Val Loss: 0.2995\n",
      "Epoch 58/100, Train Loss: 0.2876, Val Loss: 0.2937\n",
      "Epoch 59/100, Train Loss: 0.2697, Val Loss: 0.2758\n",
      "Epoch 60/100, Train Loss: 0.2566, Val Loss: 0.2619\n",
      "Epoch 61/100, Train Loss: 0.2476, Val Loss: 0.2542\n",
      "Epoch 62/100, Train Loss: 0.2522, Val Loss: 0.2587\n",
      "Epoch 63/100, Train Loss: 0.2306, Val Loss: 0.2391\n",
      "Epoch 64/100, Train Loss: 0.2255, Val Loss: 0.2347\n",
      "Epoch 65/100, Train Loss: 0.2193, Val Loss: 0.2310\n",
      "Epoch 66/100, Train Loss: 0.2172, Val Loss: 0.2300\n",
      "Epoch 67/100, Train Loss: 0.2061, Val Loss: 0.2179\n",
      "Epoch 68/100, Train Loss: 0.1980, Val Loss: 0.2124\n",
      "Epoch 69/100, Train Loss: 0.1939, Val Loss: 0.2099\n",
      "Epoch 70/100, Train Loss: 0.1859, Val Loss: 0.2001\n",
      "Epoch 71/100, Train Loss: 0.1904, Val Loss: 0.2037\n",
      "Epoch 72/100, Train Loss: 0.1772, Val Loss: 0.1962\n",
      "Epoch 73/100, Train Loss: 0.1737, Val Loss: 0.1919\n",
      "Epoch 74/100, Train Loss: 0.1788, Val Loss: 0.2002\n",
      "Epoch 75/100, Train Loss: 0.1613, Val Loss: 0.1798\n",
      "Epoch 76/100, Train Loss: 0.1589, Val Loss: 0.1817\n",
      "Epoch 77/100, Train Loss: 0.1786, Val Loss: 0.1998\n",
      "Epoch 78/100, Train Loss: 0.1490, Val Loss: 0.1723\n",
      "Epoch 79/100, Train Loss: 0.1455, Val Loss: 0.1692\n",
      "Epoch 80/100, Train Loss: 0.1455, Val Loss: 0.1718\n",
      "Epoch 81/100, Train Loss: 0.1373, Val Loss: 0.1619\n",
      "Epoch 82/100, Train Loss: 0.1343, Val Loss: 0.1590\n",
      "Epoch 83/100, Train Loss: 0.1329, Val Loss: 0.1610\n",
      "Epoch 84/100, Train Loss: 0.1286, Val Loss: 0.1570\n",
      "Epoch 85/100, Train Loss: 0.1341, Val Loss: 0.1634\n",
      "Epoch 86/100, Train Loss: 0.1200, Val Loss: 0.1496\n",
      "Epoch 87/100, Train Loss: 0.1208, Val Loss: 0.1517\n",
      "Epoch 88/100, Train Loss: 0.1200, Val Loss: 0.1524\n",
      "Epoch 89/100, Train Loss: 0.1121, Val Loss: 0.1466\n",
      "Epoch 90/100, Train Loss: 0.1169, Val Loss: 0.1516\n",
      "Epoch 91/100, Train Loss: 0.1111, Val Loss: 0.1460\n",
      "Epoch 92/100, Train Loss: 0.1085, Val Loss: 0.1395\n",
      "Epoch 93/100, Train Loss: 0.1036, Val Loss: 0.1391\n",
      "Epoch 94/100, Train Loss: 0.0987, Val Loss: 0.1351\n",
      "Epoch 95/100, Train Loss: 0.1010, Val Loss: 0.1372\n",
      "Epoch 96/100, Train Loss: 0.1043, Val Loss: 0.1396\n",
      "Epoch 97/100, Train Loss: 0.0917, Val Loss: 0.1298\n",
      "Epoch 98/100, Train Loss: 0.0959, Val Loss: 0.1316\n",
      "Epoch 99/100, Train Loss: 0.1044, Val Loss: 0.1438\n",
      "Epoch 100/100, Train Loss: 0.0862, Val Loss: 0.1261\n",
      "Epoch 3/100 - Train Loss: 0.08622822762778745 - Val Loss: 0.12613855715891722\n",
      "Epoch 1/100, Train Loss: 0.0822, Val Loss: 0.1232\n",
      "Epoch 2/100, Train Loss: 0.0823, Val Loss: 0.1223\n",
      "Epoch 3/100, Train Loss: 0.0798, Val Loss: 0.1215\n",
      "Epoch 4/100, Train Loss: 0.0791, Val Loss: 0.1239\n",
      "Epoch 5/100, Train Loss: 0.0771, Val Loss: 0.1234\n",
      "Epoch 6/100, Train Loss: 0.0742, Val Loss: 0.1202\n",
      "Epoch 7/100, Train Loss: 0.0736, Val Loss: 0.1190\n",
      "Epoch 8/100, Train Loss: 0.0708, Val Loss: 0.1172\n",
      "Epoch 9/100, Train Loss: 0.0712, Val Loss: 0.1206\n",
      "Epoch 10/100, Train Loss: 0.0703, Val Loss: 0.1180\n",
      "Epoch 11/100, Train Loss: 0.0721, Val Loss: 0.1200\n",
      "Epoch 12/100, Train Loss: 0.0687, Val Loss: 0.1156\n",
      "Epoch 13/100, Train Loss: 0.0664, Val Loss: 0.1200\n",
      "Epoch 14/100, Train Loss: 0.0668, Val Loss: 0.1177\n",
      "Epoch 15/100, Train Loss: 0.0626, Val Loss: 0.1129\n",
      "Epoch 16/100, Train Loss: 0.0624, Val Loss: 0.1133\n",
      "Epoch 17/100, Train Loss: 0.0596, Val Loss: 0.1132\n",
      "Epoch 18/100, Train Loss: 0.0640, Val Loss: 0.1170\n",
      "Epoch 19/100, Train Loss: 0.0616, Val Loss: 0.1167\n",
      "Epoch 20/100, Train Loss: 0.0631, Val Loss: 0.1132\n",
      "Epoch 21/100, Train Loss: 0.0567, Val Loss: 0.1106\n",
      "Epoch 22/100, Train Loss: 0.0542, Val Loss: 0.1067\n",
      "Epoch 23/100, Train Loss: 0.0562, Val Loss: 0.1161\n",
      "Epoch 24/100, Train Loss: 0.0557, Val Loss: 0.1096\n",
      "Epoch 25/100, Train Loss: 0.0509, Val Loss: 0.1060\n",
      "Epoch 26/100, Train Loss: 0.0526, Val Loss: 0.1118\n",
      "Epoch 27/100, Train Loss: 0.0591, Val Loss: 0.1239\n",
      "Epoch 28/100, Train Loss: 0.0474, Val Loss: 0.1055\n",
      "Epoch 29/100, Train Loss: 0.0466, Val Loss: 0.1081\n",
      "Epoch 30/100, Train Loss: 0.0456, Val Loss: 0.1066\n",
      "Epoch 31/100, Train Loss: 0.0491, Val Loss: 0.1051\n",
      "Epoch 32/100, Train Loss: 0.0477, Val Loss: 0.1044\n",
      "Epoch 33/100, Train Loss: 0.0445, Val Loss: 0.1045\n",
      "Epoch 34/100, Train Loss: 0.0473, Val Loss: 0.1071\n",
      "Epoch 35/100, Train Loss: 0.0419, Val Loss: 0.1057\n",
      "Epoch 36/100, Train Loss: 0.0413, Val Loss: 0.1039\n",
      "Epoch 37/100, Train Loss: 0.0404, Val Loss: 0.1046\n",
      "Epoch 38/100, Train Loss: 0.0439, Val Loss: 0.1073\n",
      "Epoch 39/100, Train Loss: 0.0425, Val Loss: 0.1064\n",
      "Epoch 40/100, Train Loss: 0.0392, Val Loss: 0.1024\n",
      "Epoch 41/100, Train Loss: 0.0417, Val Loss: 0.1136\n",
      "Epoch 42/100, Train Loss: 0.0386, Val Loss: 0.1037\n",
      "Epoch 43/100, Train Loss: 0.0392, Val Loss: 0.1096\n",
      "Epoch 44/100, Train Loss: 0.0351, Val Loss: 0.1042\n",
      "Epoch 45/100, Train Loss: 0.0345, Val Loss: 0.1023\n",
      "Epoch 46/100, Train Loss: 0.0349, Val Loss: 0.1073\n",
      "Epoch 47/100, Train Loss: 0.0331, Val Loss: 0.1028\n",
      "Epoch 48/100, Train Loss: 0.0324, Val Loss: 0.1026\n",
      "Epoch 49/100, Train Loss: 0.0327, Val Loss: 0.1032\n",
      "Epoch 50/100, Train Loss: 0.0341, Val Loss: 0.1046\n",
      "Epoch 51/100, Train Loss: 0.0307, Val Loss: 0.1039\n",
      "Epoch 52/100, Train Loss: 0.0301, Val Loss: 0.1052\n",
      "Epoch 53/100, Train Loss: 0.0312, Val Loss: 0.1042\n",
      "Epoch 54/100, Train Loss: 0.0323, Val Loss: 0.1006\n",
      "Epoch 55/100, Train Loss: 0.0279, Val Loss: 0.1016\n",
      "Epoch 56/100, Train Loss: 0.0284, Val Loss: 0.1060\n",
      "Epoch 57/100, Train Loss: 0.0273, Val Loss: 0.1055\n",
      "Epoch 58/100, Train Loss: 0.0281, Val Loss: 0.1036\n",
      "Epoch 59/100, Train Loss: 0.0279, Val Loss: 0.1064\n",
      "Epoch 60/100, Train Loss: 0.0272, Val Loss: 0.1017\n",
      "Epoch 61/100, Train Loss: 0.0279, Val Loss: 0.1088\n",
      "Epoch 62/100, Train Loss: 0.0276, Val Loss: 0.1113\n",
      "Epoch 63/100, Train Loss: 0.0239, Val Loss: 0.1018\n",
      "Epoch 64/100, Train Loss: 0.0236, Val Loss: 0.1043\n",
      "Early stopping triggered at epoch 64\n",
      "Epoch 4/100 - Train Loss: 0.023621048172586787 - Val Loss: 0.10433636911879043\n",
      "Epoch 1/100, Train Loss: 0.0240, Val Loss: 0.1042\n",
      "Epoch 2/100, Train Loss: 0.0225, Val Loss: 0.1036\n",
      "Epoch 3/100, Train Loss: 0.0233, Val Loss: 0.1038\n",
      "Epoch 4/100, Train Loss: 0.0223, Val Loss: 0.1035\n",
      "Epoch 5/100, Train Loss: 0.0223, Val Loss: 0.1062\n",
      "Epoch 6/100, Train Loss: 0.0224, Val Loss: 0.1026\n",
      "Epoch 7/100, Train Loss: 0.0296, Val Loss: 0.1191\n",
      "Epoch 8/100, Train Loss: 0.0279, Val Loss: 0.1150\n",
      "Epoch 9/100, Train Loss: 0.0205, Val Loss: 0.1067\n",
      "Epoch 10/100, Train Loss: 0.0208, Val Loss: 0.1043\n",
      "Epoch 11/100, Train Loss: 0.0193, Val Loss: 0.1038\n",
      "Epoch 12/100, Train Loss: 0.0185, Val Loss: 0.1041\n",
      "Epoch 13/100, Train Loss: 0.0198, Val Loss: 0.1034\n",
      "Epoch 14/100, Train Loss: 0.0191, Val Loss: 0.1058\n",
      "Epoch 15/100, Train Loss: 0.0176, Val Loss: 0.1036\n",
      "Epoch 16/100, Train Loss: 0.0178, Val Loss: 0.1049\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 5/100 - Train Loss: 0.017771027406265877 - Val Loss: 0.10486984670575908\n",
      "Epoch 1/100, Train Loss: 0.0193, Val Loss: 0.1043\n",
      "Epoch 2/100, Train Loss: 0.0171, Val Loss: 0.1067\n",
      "Epoch 3/100, Train Loss: 0.0162, Val Loss: 0.1038\n",
      "Epoch 4/100, Train Loss: 0.0172, Val Loss: 0.1089\n",
      "Epoch 5/100, Train Loss: 0.0168, Val Loss: 0.1065\n",
      "Epoch 6/100, Train Loss: 0.0162, Val Loss: 0.1030\n",
      "Epoch 7/100, Train Loss: 0.0197, Val Loss: 0.1154\n",
      "Epoch 8/100, Train Loss: 0.0157, Val Loss: 0.1057\n",
      "Epoch 9/100, Train Loss: 0.0146, Val Loss: 0.1030\n",
      "Epoch 10/100, Train Loss: 0.0149, Val Loss: 0.1024\n",
      "Epoch 11/100, Train Loss: 0.0151, Val Loss: 0.1078\n",
      "Epoch 12/100, Train Loss: 0.0144, Val Loss: 0.1056\n",
      "Epoch 13/100, Train Loss: 0.0142, Val Loss: 0.1053\n",
      "Epoch 14/100, Train Loss: 0.0133, Val Loss: 0.1047\n",
      "Epoch 15/100, Train Loss: 0.0131, Val Loss: 0.1050\n",
      "Epoch 16/100, Train Loss: 0.0127, Val Loss: 0.1060\n",
      "Epoch 17/100, Train Loss: 0.0131, Val Loss: 0.1034\n",
      "Epoch 18/100, Train Loss: 0.0133, Val Loss: 0.1072\n",
      "Epoch 19/100, Train Loss: 0.0122, Val Loss: 0.1055\n",
      "Epoch 20/100, Train Loss: 0.0122, Val Loss: 0.1041\n",
      "Early stopping triggered at epoch 20\n",
      "Epoch 6/100 - Train Loss: 0.012168671241570369 - Val Loss: 0.10411502651706712\n",
      "Epoch 1/100, Train Loss: 0.0122, Val Loss: 0.1056\n",
      "Epoch 2/100, Train Loss: 0.0116, Val Loss: 0.1063\n",
      "Epoch 3/100, Train Loss: 0.0114, Val Loss: 0.1064\n",
      "Epoch 4/100, Train Loss: 0.0115, Val Loss: 0.1056\n",
      "Epoch 5/100, Train Loss: 0.0110, Val Loss: 0.1042\n",
      "Epoch 6/100, Train Loss: 0.0108, Val Loss: 0.1055\n",
      "Epoch 7/100, Train Loss: 0.0106, Val Loss: 0.1067\n",
      "Epoch 8/100, Train Loss: 0.0105, Val Loss: 0.1071\n",
      "Epoch 9/100, Train Loss: 0.0100, Val Loss: 0.1054\n",
      "Epoch 10/100, Train Loss: 0.0107, Val Loss: 0.1064\n",
      "Epoch 11/100, Train Loss: 0.0106, Val Loss: 0.1090\n",
      "Epoch 12/100, Train Loss: 0.0102, Val Loss: 0.1070\n",
      "Epoch 13/100, Train Loss: 0.0111, Val Loss: 0.1099\n",
      "Epoch 14/100, Train Loss: 0.0092, Val Loss: 0.1063\n",
      "Epoch 15/100, Train Loss: 0.0096, Val Loss: 0.1068\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 7/100 - Train Loss: 0.00962199231401853 - Val Loss: 0.10676000317265553\n",
      "Epoch 1/100, Train Loss: 0.0094, Val Loss: 0.1076\n",
      "Epoch 2/100, Train Loss: 0.0097, Val Loss: 0.1071\n",
      "Epoch 3/100, Train Loss: 0.0092, Val Loss: 0.1087\n",
      "Epoch 4/100, Train Loss: 0.0087, Val Loss: 0.1070\n",
      "Epoch 5/100, Train Loss: 0.0086, Val Loss: 0.1077\n",
      "Epoch 6/100, Train Loss: 0.0090, Val Loss: 0.1108\n",
      "Epoch 7/100, Train Loss: 0.0089, Val Loss: 0.1058\n",
      "Epoch 8/100, Train Loss: 0.0086, Val Loss: 0.1084\n",
      "Epoch 9/100, Train Loss: 0.0081, Val Loss: 0.1092\n",
      "Epoch 10/100, Train Loss: 0.0084, Val Loss: 0.1085\n",
      "Epoch 11/100, Train Loss: 0.0079, Val Loss: 0.1083\n",
      "Epoch 12/100, Train Loss: 0.0082, Val Loss: 0.1086\n",
      "Epoch 13/100, Train Loss: 0.0088, Val Loss: 0.1068\n",
      "Epoch 14/100, Train Loss: 0.0078, Val Loss: 0.1100\n",
      "Epoch 15/100, Train Loss: 0.0073, Val Loss: 0.1079\n",
      "Epoch 16/100, Train Loss: 0.0077, Val Loss: 0.1105\n",
      "Epoch 17/100, Train Loss: 0.0070, Val Loss: 0.1080\n",
      "Early stopping triggered at epoch 17\n",
      "Epoch 8/100 - Train Loss: 0.006991985964548327 - Val Loss: 0.10800730021450895\n",
      "Epoch 1/100, Train Loss: 0.0077, Val Loss: 0.1114\n",
      "Epoch 2/100, Train Loss: 0.0069, Val Loss: 0.1088\n",
      "Epoch 3/100, Train Loss: 0.0067, Val Loss: 0.1073\n",
      "Epoch 4/100, Train Loss: 0.0067, Val Loss: 0.1095\n",
      "Epoch 5/100, Train Loss: 0.0066, Val Loss: 0.1100\n",
      "Epoch 6/100, Train Loss: 0.0066, Val Loss: 0.1101\n",
      "Epoch 7/100, Train Loss: 0.0071, Val Loss: 0.1108\n",
      "Epoch 8/100, Train Loss: 0.0067, Val Loss: 0.1103\n",
      "Epoch 9/100, Train Loss: 0.0064, Val Loss: 0.1097\n",
      "Epoch 10/100, Train Loss: 0.0061, Val Loss: 0.1092\n",
      "Epoch 11/100, Train Loss: 0.0064, Val Loss: 0.1090\n",
      "Epoch 12/100, Train Loss: 0.0060, Val Loss: 0.1096\n",
      "Epoch 13/100, Train Loss: 0.0062, Val Loss: 0.1104\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 9/100 - Train Loss: 0.006184292572690596 - Val Loss: 0.11039878596620205\n",
      "Epoch 1/100, Train Loss: 0.0062, Val Loss: 0.1111\n",
      "Epoch 2/100, Train Loss: 0.0059, Val Loss: 0.1105\n",
      "Epoch 3/100, Train Loss: 0.0063, Val Loss: 0.1100\n",
      "Epoch 4/100, Train Loss: 0.0057, Val Loss: 0.1086\n",
      "Epoch 5/100, Train Loss: 0.0059, Val Loss: 0.1115\n",
      "Epoch 6/100, Train Loss: 0.0056, Val Loss: 0.1089\n",
      "Epoch 7/100, Train Loss: 0.0056, Val Loss: 0.1102\n",
      "Epoch 8/100, Train Loss: 0.0054, Val Loss: 0.1101\n",
      "Epoch 9/100, Train Loss: 0.0055, Val Loss: 0.1107\n",
      "Epoch 10/100, Train Loss: 0.0054, Val Loss: 0.1118\n",
      "Epoch 11/100, Train Loss: 0.0052, Val Loss: 0.1102\n",
      "Epoch 12/100, Train Loss: 0.0051, Val Loss: 0.1106\n",
      "Epoch 13/100, Train Loss: 0.0052, Val Loss: 0.1113\n",
      "Epoch 14/100, Train Loss: 0.0051, Val Loss: 0.1109\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 10/100 - Train Loss: 0.005126863072240737 - Val Loss: 0.11086564652619599\n",
      "Epoch 1/100, Train Loss: 0.0051, Val Loss: 0.1117\n",
      "Epoch 2/100, Train Loss: 0.0049, Val Loss: 0.1115\n",
      "Epoch 3/100, Train Loss: 0.0049, Val Loss: 0.1114\n",
      "Epoch 4/100, Train Loss: 0.0049, Val Loss: 0.1104\n",
      "Epoch 5/100, Train Loss: 0.0049, Val Loss: 0.1111\n",
      "Epoch 6/100, Train Loss: 0.0048, Val Loss: 0.1126\n",
      "Epoch 7/100, Train Loss: 0.0047, Val Loss: 0.1112\n",
      "Epoch 8/100, Train Loss: 0.0046, Val Loss: 0.1107\n",
      "Epoch 9/100, Train Loss: 0.0048, Val Loss: 0.1135\n",
      "Epoch 10/100, Train Loss: 0.0047, Val Loss: 0.1110\n",
      "Epoch 11/100, Train Loss: 0.0045, Val Loss: 0.1116\n",
      "Epoch 12/100, Train Loss: 0.0046, Val Loss: 0.1128\n",
      "Epoch 13/100, Train Loss: 0.0044, Val Loss: 0.1117\n",
      "Epoch 14/100, Train Loss: 0.0044, Val Loss: 0.1129\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 11/100 - Train Loss: 0.0043835980046780815 - Val Loss: 0.1129275262119448\n",
      "Epoch 1/100, Train Loss: 0.0044, Val Loss: 0.1109\n",
      "Epoch 2/100, Train Loss: 0.0043, Val Loss: 0.1112\n",
      "Epoch 3/100, Train Loss: 0.0043, Val Loss: 0.1108\n",
      "Epoch 4/100, Train Loss: 0.0043, Val Loss: 0.1131\n",
      "Epoch 5/100, Train Loss: 0.0042, Val Loss: 0.1123\n",
      "Epoch 6/100, Train Loss: 0.0041, Val Loss: 0.1126\n",
      "Epoch 7/100, Train Loss: 0.0042, Val Loss: 0.1120\n",
      "Epoch 8/100, Train Loss: 0.0041, Val Loss: 0.1129\n",
      "Epoch 9/100, Train Loss: 0.0043, Val Loss: 0.1138\n",
      "Epoch 10/100, Train Loss: 0.0040, Val Loss: 0.1116\n",
      "Epoch 11/100, Train Loss: 0.0042, Val Loss: 0.1140\n",
      "Epoch 12/100, Train Loss: 0.0040, Val Loss: 0.1136\n",
      "Epoch 13/100, Train Loss: 0.0039, Val Loss: 0.1124\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 12/100 - Train Loss: 0.003888080126562511 - Val Loss: 0.11237593020140531\n",
      "Epoch 1/100, Train Loss: 0.0039, Val Loss: 0.1131\n",
      "Epoch 2/100, Train Loss: 0.0040, Val Loss: 0.1136\n",
      "Epoch 3/100, Train Loss: 0.0041, Val Loss: 0.1127\n",
      "Epoch 4/100, Train Loss: 0.0038, Val Loss: 0.1127\n",
      "Epoch 5/100, Train Loss: 0.0038, Val Loss: 0.1120\n",
      "Epoch 6/100, Train Loss: 0.0038, Val Loss: 0.1144\n",
      "Epoch 7/100, Train Loss: 0.0037, Val Loss: 0.1125\n",
      "Epoch 8/100, Train Loss: 0.0037, Val Loss: 0.1126\n",
      "Epoch 9/100, Train Loss: 0.0037, Val Loss: 0.1154\n",
      "Epoch 10/100, Train Loss: 0.0037, Val Loss: 0.1133\n",
      "Epoch 11/100, Train Loss: 0.0036, Val Loss: 0.1135\n",
      "Epoch 12/100, Train Loss: 0.0036, Val Loss: 0.1132\n",
      "Epoch 13/100, Train Loss: 0.0035, Val Loss: 0.1128\n",
      "Epoch 14/100, Train Loss: 0.0035, Val Loss: 0.1126\n",
      "Epoch 15/100, Train Loss: 0.0034, Val Loss: 0.1129\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 13/100 - Train Loss: 0.003410230302466732 - Val Loss: 0.11290987441718996\n",
      "Epoch 1/100, Train Loss: 0.0034, Val Loss: 0.1132\n",
      "Epoch 2/100, Train Loss: 0.0034, Val Loss: 0.1137\n",
      "Epoch 3/100, Train Loss: 0.0033, Val Loss: 0.1129\n",
      "Epoch 4/100, Train Loss: 0.0034, Val Loss: 0.1126\n",
      "Epoch 5/100, Train Loss: 0.0033, Val Loss: 0.1136\n",
      "Epoch 6/100, Train Loss: 0.0033, Val Loss: 0.1145\n",
      "Epoch 7/100, Train Loss: 0.0032, Val Loss: 0.1129\n",
      "Epoch 8/100, Train Loss: 0.0032, Val Loss: 0.1138\n",
      "Epoch 9/100, Train Loss: 0.0032, Val Loss: 0.1149\n",
      "Epoch 10/100, Train Loss: 0.0031, Val Loss: 0.1143\n",
      "Epoch 11/100, Train Loss: 0.0032, Val Loss: 0.1153\n",
      "Epoch 12/100, Train Loss: 0.0031, Val Loss: 0.1135\n",
      "Epoch 13/100, Train Loss: 0.0031, Val Loss: 0.1140\n",
      "Epoch 14/100, Train Loss: 0.0030, Val Loss: 0.1139\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 14/100 - Train Loss: 0.0030446144332319336 - Val Loss: 0.11389310549678297\n",
      "Epoch 1/100, Train Loss: 0.0030, Val Loss: 0.1143\n",
      "Epoch 2/100, Train Loss: 0.0030, Val Loss: 0.1140\n",
      "Epoch 3/100, Train Loss: 0.0030, Val Loss: 0.1140\n",
      "Epoch 4/100, Train Loss: 0.0030, Val Loss: 0.1144\n",
      "Epoch 5/100, Train Loss: 0.0029, Val Loss: 0.1145\n",
      "Epoch 6/100, Train Loss: 0.0029, Val Loss: 0.1149\n",
      "Epoch 7/100, Train Loss: 0.0029, Val Loss: 0.1153\n",
      "Epoch 8/100, Train Loss: 0.0029, Val Loss: 0.1141\n",
      "Epoch 9/100, Train Loss: 0.0028, Val Loss: 0.1151\n",
      "Epoch 10/100, Train Loss: 0.0028, Val Loss: 0.1152\n",
      "Epoch 11/100, Train Loss: 0.0028, Val Loss: 0.1157\n",
      "Epoch 12/100, Train Loss: 0.0027, Val Loss: 0.1153\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 15/100 - Train Loss: 0.002749714106152577 - Val Loss: 0.11525456823649396\n",
      "Epoch 1/100, Train Loss: 0.0027, Val Loss: 0.1150\n",
      "Epoch 2/100, Train Loss: 0.0027, Val Loss: 0.1147\n",
      "Epoch 3/100, Train Loss: 0.0027, Val Loss: 0.1146\n",
      "Epoch 4/100, Train Loss: 0.0027, Val Loss: 0.1156\n",
      "Epoch 5/100, Train Loss: 0.0026, Val Loss: 0.1155\n",
      "Epoch 6/100, Train Loss: 0.0026, Val Loss: 0.1150\n",
      "Epoch 7/100, Train Loss: 0.0026, Val Loss: 0.1147\n",
      "Epoch 8/100, Train Loss: 0.0026, Val Loss: 0.1160\n",
      "Epoch 9/100, Train Loss: 0.0026, Val Loss: 0.1147\n",
      "Epoch 10/100, Train Loss: 0.0025, Val Loss: 0.1154\n",
      "Epoch 11/100, Train Loss: 0.0025, Val Loss: 0.1155\n",
      "Epoch 12/100, Train Loss: 0.0025, Val Loss: 0.1147\n",
      "Epoch 13/100, Train Loss: 0.0025, Val Loss: 0.1143\n",
      "Epoch 14/100, Train Loss: 0.0025, Val Loss: 0.1166\n",
      "Epoch 15/100, Train Loss: 0.0026, Val Loss: 0.1158\n",
      "Epoch 16/100, Train Loss: 0.0025, Val Loss: 0.1149\n",
      "Epoch 17/100, Train Loss: 0.0024, Val Loss: 0.1161\n",
      "Epoch 18/100, Train Loss: 0.0024, Val Loss: 0.1163\n",
      "Epoch 19/100, Train Loss: 0.0024, Val Loss: 0.1156\n",
      "Epoch 20/100, Train Loss: 0.0023, Val Loss: 0.1154\n",
      "Epoch 21/100, Train Loss: 0.0023, Val Loss: 0.1154\n",
      "Epoch 22/100, Train Loss: 0.0023, Val Loss: 0.1160\n",
      "Epoch 23/100, Train Loss: 0.0023, Val Loss: 0.1163\n",
      "Early stopping triggered at epoch 23\n",
      "Epoch 16/100 - Train Loss: 0.0023062151142283637 - Val Loss: 0.11633123672210748\n",
      "Epoch 1/100, Train Loss: 0.0023, Val Loss: 0.1165\n",
      "Epoch 2/100, Train Loss: 0.0023, Val Loss: 0.1163\n",
      "Epoch 3/100, Train Loss: 0.0022, Val Loss: 0.1157\n",
      "Epoch 4/100, Train Loss: 0.0023, Val Loss: 0.1162\n",
      "Epoch 5/100, Train Loss: 0.0022, Val Loss: 0.1161\n",
      "Epoch 6/100, Train Loss: 0.0023, Val Loss: 0.1163\n",
      "Epoch 7/100, Train Loss: 0.0022, Val Loss: 0.1165\n",
      "Epoch 8/100, Train Loss: 0.0022, Val Loss: 0.1161\n",
      "Epoch 9/100, Train Loss: 0.0023, Val Loss: 0.1172\n",
      "Epoch 10/100, Train Loss: 0.0022, Val Loss: 0.1164\n",
      "Epoch 11/100, Train Loss: 0.0021, Val Loss: 0.1162\n",
      "Epoch 12/100, Train Loss: 0.0022, Val Loss: 0.1169\n",
      "Epoch 13/100, Train Loss: 0.0022, Val Loss: 0.1167\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 17/100 - Train Loss: 0.002159977044228118 - Val Loss: 0.11668380805519656\n",
      "Epoch 1/100, Train Loss: 0.0021, Val Loss: 0.1161\n",
      "Epoch 2/100, Train Loss: 0.0021, Val Loss: 0.1175\n",
      "Epoch 3/100, Train Loss: 0.0021, Val Loss: 0.1162\n",
      "Epoch 4/100, Train Loss: 0.0020, Val Loss: 0.1163\n",
      "Epoch 5/100, Train Loss: 0.0021, Val Loss: 0.1180\n",
      "Epoch 6/100, Train Loss: 0.0021, Val Loss: 0.1175\n",
      "Epoch 7/100, Train Loss: 0.0020, Val Loss: 0.1170\n",
      "Epoch 8/100, Train Loss: 0.0020, Val Loss: 0.1163\n",
      "Epoch 9/100, Train Loss: 0.0020, Val Loss: 0.1167\n",
      "Epoch 10/100, Train Loss: 0.0020, Val Loss: 0.1170\n",
      "Epoch 11/100, Train Loss: 0.0020, Val Loss: 0.1165\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 18/100 - Train Loss: 0.001970957630930738 - Val Loss: 0.11649522381557438\n",
      "Epoch 1/100, Train Loss: 0.0020, Val Loss: 0.1175\n",
      "Epoch 2/100, Train Loss: 0.0020, Val Loss: 0.1179\n",
      "Epoch 3/100, Train Loss: 0.0020, Val Loss: 0.1177\n",
      "Epoch 4/100, Train Loss: 0.0020, Val Loss: 0.1174\n",
      "Epoch 5/100, Train Loss: 0.0019, Val Loss: 0.1179\n",
      "Epoch 6/100, Train Loss: 0.0019, Val Loss: 0.1175\n",
      "Epoch 7/100, Train Loss: 0.0019, Val Loss: 0.1172\n",
      "Epoch 8/100, Train Loss: 0.0019, Val Loss: 0.1162\n",
      "Epoch 9/100, Train Loss: 0.0019, Val Loss: 0.1176\n",
      "Epoch 10/100, Train Loss: 0.0019, Val Loss: 0.1176\n",
      "Epoch 11/100, Train Loss: 0.0019, Val Loss: 0.1179\n",
      "Epoch 12/100, Train Loss: 0.0019, Val Loss: 0.1181\n",
      "Epoch 13/100, Train Loss: 0.0018, Val Loss: 0.1179\n",
      "Epoch 14/100, Train Loss: 0.0018, Val Loss: 0.1176\n",
      "Epoch 15/100, Train Loss: 0.0018, Val Loss: 0.1185\n",
      "Epoch 16/100, Train Loss: 0.0018, Val Loss: 0.1168\n",
      "Epoch 17/100, Train Loss: 0.0018, Val Loss: 0.1175\n",
      "Epoch 18/100, Train Loss: 0.0018, Val Loss: 0.1185\n",
      "Early stopping triggered at epoch 18\n",
      "Epoch 19/100 - Train Loss: 0.0018051003131673753 - Val Loss: 0.11847598171866729\n",
      "Epoch 1/100, Train Loss: 0.0018, Val Loss: 0.1185\n",
      "Epoch 2/100, Train Loss: 0.0018, Val Loss: 0.1179\n",
      "Epoch 3/100, Train Loss: 0.0018, Val Loss: 0.1183\n",
      "Epoch 4/100, Train Loss: 0.0018, Val Loss: 0.1182\n",
      "Epoch 5/100, Train Loss: 0.0018, Val Loss: 0.1182\n",
      "Epoch 6/100, Train Loss: 0.0017, Val Loss: 0.1179\n",
      "Epoch 7/100, Train Loss: 0.0017, Val Loss: 0.1179\n",
      "Epoch 8/100, Train Loss: 0.0017, Val Loss: 0.1182\n",
      "Epoch 9/100, Train Loss: 0.0017, Val Loss: 0.1181\n",
      "Epoch 10/100, Train Loss: 0.0017, Val Loss: 0.1185\n",
      "Epoch 11/100, Train Loss: 0.0017, Val Loss: 0.1191\n",
      "Epoch 12/100, Train Loss: 0.0017, Val Loss: 0.1187\n",
      "Epoch 13/100, Train Loss: 0.0017, Val Loss: 0.1193\n",
      "Epoch 14/100, Train Loss: 0.0017, Val Loss: 0.1180\n",
      "Epoch 15/100, Train Loss: 0.0017, Val Loss: 0.1182\n",
      "Epoch 16/100, Train Loss: 0.0017, Val Loss: 0.1186\n",
      "Epoch 17/100, Train Loss: 0.0016, Val Loss: 0.1186\n",
      "Early stopping triggered at epoch 17\n",
      "Epoch 20/100 - Train Loss: 0.0016433627478360678 - Val Loss: 0.11856307268712407\n",
      "Epoch 1/100, Train Loss: 0.0016, Val Loss: 0.1191\n",
      "Epoch 2/100, Train Loss: 0.0016, Val Loss: 0.1193\n",
      "Epoch 3/100, Train Loss: 0.0016, Val Loss: 0.1192\n",
      "Epoch 4/100, Train Loss: 0.0016, Val Loss: 0.1190\n",
      "Epoch 5/100, Train Loss: 0.0016, Val Loss: 0.1188\n",
      "Epoch 6/100, Train Loss: 0.0016, Val Loss: 0.1197\n",
      "Epoch 7/100, Train Loss: 0.0016, Val Loss: 0.1189\n",
      "Epoch 8/100, Train Loss: 0.0016, Val Loss: 0.1193\n",
      "Epoch 9/100, Train Loss: 0.0016, Val Loss: 0.1200\n",
      "Epoch 10/100, Train Loss: 0.0016, Val Loss: 0.1191\n",
      "Epoch 11/100, Train Loss: 0.0016, Val Loss: 0.1193\n",
      "Epoch 12/100, Train Loss: 0.0016, Val Loss: 0.1198\n",
      "Epoch 13/100, Train Loss: 0.0016, Val Loss: 0.1203\n",
      "Epoch 14/100, Train Loss: 0.0015, Val Loss: 0.1194\n",
      "Epoch 15/100, Train Loss: 0.0015, Val Loss: 0.1194\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 21/100 - Train Loss: 0.0015277799912979141 - Val Loss: 0.11940110190717762\n",
      "Epoch 1/100, Train Loss: 0.0015, Val Loss: 0.1193\n",
      "Epoch 2/100, Train Loss: 0.0015, Val Loss: 0.1194\n",
      "Epoch 3/100, Train Loss: 0.0015, Val Loss: 0.1196\n",
      "Epoch 4/100, Train Loss: 0.0015, Val Loss: 0.1199\n",
      "Epoch 5/100, Train Loss: 0.0015, Val Loss: 0.1199\n",
      "Epoch 6/100, Train Loss: 0.0015, Val Loss: 0.1197\n",
      "Epoch 7/100, Train Loss: 0.0015, Val Loss: 0.1200\n",
      "Epoch 8/100, Train Loss: 0.0015, Val Loss: 0.1200\n",
      "Epoch 9/100, Train Loss: 0.0015, Val Loss: 0.1199\n",
      "Epoch 10/100, Train Loss: 0.0015, Val Loss: 0.1204\n",
      "Epoch 11/100, Train Loss: 0.0014, Val Loss: 0.1199\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 22/100 - Train Loss: 0.0014408696220259284 - Val Loss: 0.11989461221357572\n",
      "Epoch 1/100, Train Loss: 0.0015, Val Loss: 0.1212\n",
      "Epoch 2/100, Train Loss: 0.0014, Val Loss: 0.1206\n",
      "Epoch 3/100, Train Loss: 0.0014, Val Loss: 0.1201\n",
      "Epoch 4/100, Train Loss: 0.0014, Val Loss: 0.1204\n",
      "Epoch 5/100, Train Loss: 0.0014, Val Loss: 0.1202\n",
      "Epoch 6/100, Train Loss: 0.0014, Val Loss: 0.1201\n",
      "Epoch 7/100, Train Loss: 0.0014, Val Loss: 0.1204\n",
      "Epoch 8/100, Train Loss: 0.0014, Val Loss: 0.1203\n",
      "Epoch 9/100, Train Loss: 0.0014, Val Loss: 0.1202\n",
      "Epoch 10/100, Train Loss: 0.0014, Val Loss: 0.1199\n",
      "Epoch 11/100, Train Loss: 0.0014, Val Loss: 0.1209\n",
      "Epoch 12/100, Train Loss: 0.0014, Val Loss: 0.1208\n",
      "Epoch 13/100, Train Loss: 0.0014, Val Loss: 0.1203\n",
      "Epoch 14/100, Train Loss: 0.0013, Val Loss: 0.1207\n",
      "Epoch 15/100, Train Loss: 0.0013, Val Loss: 0.1211\n",
      "Epoch 16/100, Train Loss: 0.0013, Val Loss: 0.1213\n",
      "Epoch 17/100, Train Loss: 0.0013, Val Loss: 0.1209\n",
      "Epoch 18/100, Train Loss: 0.0013, Val Loss: 0.1205\n",
      "Epoch 19/100, Train Loss: 0.0013, Val Loss: 0.1213\n",
      "Epoch 20/100, Train Loss: 0.0013, Val Loss: 0.1213\n",
      "Early stopping triggered at epoch 20\n",
      "Epoch 23/100 - Train Loss: 0.0012874420447791205 - Val Loss: 0.12127270794215511\n",
      "Epoch 1/100, Train Loss: 0.0013, Val Loss: 0.1219\n",
      "Epoch 2/100, Train Loss: 0.0013, Val Loss: 0.1209\n",
      "Epoch 3/100, Train Loss: 0.0013, Val Loss: 0.1221\n",
      "Epoch 4/100, Train Loss: 0.0013, Val Loss: 0.1208\n",
      "Epoch 5/100, Train Loss: 0.0013, Val Loss: 0.1212\n",
      "Epoch 6/100, Train Loss: 0.0013, Val Loss: 0.1224\n",
      "Epoch 7/100, Train Loss: 0.0012, Val Loss: 0.1214\n",
      "Epoch 8/100, Train Loss: 0.0012, Val Loss: 0.1211\n",
      "Epoch 9/100, Train Loss: 0.0012, Val Loss: 0.1218\n",
      "Epoch 10/100, Train Loss: 0.0012, Val Loss: 0.1220\n",
      "Epoch 11/100, Train Loss: 0.0012, Val Loss: 0.1220\n",
      "Epoch 12/100, Train Loss: 0.0012, Val Loss: 0.1217\n",
      "Epoch 13/100, Train Loss: 0.0012, Val Loss: 0.1227\n",
      "Epoch 14/100, Train Loss: 0.0012, Val Loss: 0.1221\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 24/100 - Train Loss: 0.0012116813301728876 - Val Loss: 0.12214641390956081\n",
      "Epoch 1/100, Train Loss: 0.0012, Val Loss: 0.1220\n",
      "Epoch 2/100, Train Loss: 0.0012, Val Loss: 0.1219\n",
      "Epoch 3/100, Train Loss: 0.0012, Val Loss: 0.1217\n",
      "Epoch 4/100, Train Loss: 0.0012, Val Loss: 0.1217\n",
      "Epoch 5/100, Train Loss: 0.0012, Val Loss: 0.1214\n",
      "Epoch 6/100, Train Loss: 0.0012, Val Loss: 0.1214\n",
      "Epoch 7/100, Train Loss: 0.0012, Val Loss: 0.1224\n",
      "Epoch 8/100, Train Loss: 0.0012, Val Loss: 0.1226\n",
      "Epoch 9/100, Train Loss: 0.0012, Val Loss: 0.1217\n",
      "Epoch 10/100, Train Loss: 0.0012, Val Loss: 0.1221\n",
      "Epoch 11/100, Train Loss: 0.0012, Val Loss: 0.1221\n",
      "Epoch 12/100, Train Loss: 0.0011, Val Loss: 0.1226\n",
      "Epoch 13/100, Train Loss: 0.0011, Val Loss: 0.1214\n",
      "Epoch 14/100, Train Loss: 0.0011, Val Loss: 0.1221\n",
      "Epoch 15/100, Train Loss: 0.0011, Val Loss: 0.1218\n",
      "Epoch 16/100, Train Loss: 0.0011, Val Loss: 0.1223\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 25/100 - Train Loss: 0.0011354021164907066 - Val Loss: 0.12228408447428192\n",
      "Epoch 1/100, Train Loss: 0.0011, Val Loss: 0.1218\n",
      "Epoch 2/100, Train Loss: 0.0011, Val Loss: 0.1222\n",
      "Epoch 3/100, Train Loss: 0.0011, Val Loss: 0.1220\n",
      "Epoch 4/100, Train Loss: 0.0011, Val Loss: 0.1222\n",
      "Epoch 5/100, Train Loss: 0.0011, Val Loss: 0.1222\n",
      "Epoch 6/100, Train Loss: 0.0011, Val Loss: 0.1221\n",
      "Epoch 7/100, Train Loss: 0.0011, Val Loss: 0.1223\n",
      "Epoch 8/100, Train Loss: 0.0011, Val Loss: 0.1220\n",
      "Epoch 9/100, Train Loss: 0.0011, Val Loss: 0.1230\n",
      "Epoch 10/100, Train Loss: 0.0011, Val Loss: 0.1224\n",
      "Epoch 11/100, Train Loss: 0.0011, Val Loss: 0.1221\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 26/100 - Train Loss: 0.0010798056628764897 - Val Loss: 0.12206591717150941\n",
      "Epoch 1/100, Train Loss: 0.0011, Val Loss: 0.1227\n",
      "Epoch 2/100, Train Loss: 0.0011, Val Loss: 0.1226\n",
      "Epoch 3/100, Train Loss: 0.0011, Val Loss: 0.1225\n",
      "Epoch 4/100, Train Loss: 0.0011, Val Loss: 0.1221\n",
      "Epoch 5/100, Train Loss: 0.0011, Val Loss: 0.1220\n",
      "Epoch 6/100, Train Loss: 0.0011, Val Loss: 0.1225\n",
      "Epoch 7/100, Train Loss: 0.0011, Val Loss: 0.1225\n",
      "Epoch 8/100, Train Loss: 0.0010, Val Loss: 0.1228\n",
      "Epoch 9/100, Train Loss: 0.0010, Val Loss: 0.1229\n",
      "Epoch 10/100, Train Loss: 0.0010, Val Loss: 0.1234\n",
      "Epoch 11/100, Train Loss: 0.0010, Val Loss: 0.1225\n",
      "Epoch 12/100, Train Loss: 0.0010, Val Loss: 0.1229\n",
      "Epoch 13/100, Train Loss: 0.0010, Val Loss: 0.1231\n",
      "Epoch 14/100, Train Loss: 0.0010, Val Loss: 0.1226\n",
      "Epoch 15/100, Train Loss: 0.0010, Val Loss: 0.1230\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 27/100 - Train Loss: 0.0010336043081381773 - Val Loss: 0.12296066369022553\n",
      "Epoch 1/100, Train Loss: 0.0010, Val Loss: 0.1225\n",
      "Epoch 2/100, Train Loss: 0.0010, Val Loss: 0.1227\n",
      "Epoch 3/100, Train Loss: 0.0010, Val Loss: 0.1225\n",
      "Epoch 4/100, Train Loss: 0.0010, Val Loss: 0.1231\n",
      "Epoch 5/100, Train Loss: 0.0010, Val Loss: 0.1228\n",
      "Epoch 6/100, Train Loss: 0.0010, Val Loss: 0.1230\n",
      "Epoch 7/100, Train Loss: 0.0010, Val Loss: 0.1232\n",
      "Epoch 8/100, Train Loss: 0.0010, Val Loss: 0.1225\n",
      "Epoch 9/100, Train Loss: 0.0010, Val Loss: 0.1233\n",
      "Epoch 10/100, Train Loss: 0.0010, Val Loss: 0.1228\n",
      "Epoch 11/100, Train Loss: 0.0010, Val Loss: 0.1225\n",
      "Epoch 12/100, Train Loss: 0.0010, Val Loss: 0.1232\n",
      "Epoch 13/100, Train Loss: 0.0010, Val Loss: 0.1236\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 28/100 - Train Loss: 0.0009823379693387909 - Val Loss: 0.12362671218940746\n",
      "Epoch 1/100, Train Loss: 0.0010, Val Loss: 0.1234\n",
      "Epoch 2/100, Train Loss: 0.0010, Val Loss: 0.1234\n",
      "Epoch 3/100, Train Loss: 0.0010, Val Loss: 0.1235\n",
      "Epoch 4/100, Train Loss: 0.0010, Val Loss: 0.1236\n",
      "Epoch 5/100, Train Loss: 0.0010, Val Loss: 0.1235\n",
      "Epoch 6/100, Train Loss: 0.0010, Val Loss: 0.1230\n",
      "Epoch 7/100, Train Loss: 0.0010, Val Loss: 0.1233\n",
      "Epoch 8/100, Train Loss: 0.0010, Val Loss: 0.1236\n",
      "Epoch 9/100, Train Loss: 0.0010, Val Loss: 0.1236\n",
      "Epoch 10/100, Train Loss: 0.0009, Val Loss: 0.1234\n",
      "Epoch 11/100, Train Loss: 0.0009, Val Loss: 0.1233\n",
      "Epoch 12/100, Train Loss: 0.0009, Val Loss: 0.1236\n",
      "Epoch 13/100, Train Loss: 0.0009, Val Loss: 0.1236\n",
      "Epoch 14/100, Train Loss: 0.0009, Val Loss: 0.1238\n",
      "Epoch 15/100, Train Loss: 0.0009, Val Loss: 0.1235\n",
      "Epoch 16/100, Train Loss: 0.0009, Val Loss: 0.1237\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 29/100 - Train Loss: 0.0009284881987467803 - Val Loss: 0.12373628923963613\n",
      "Epoch 1/100, Train Loss: 0.0009, Val Loss: 0.1240\n",
      "Epoch 2/100, Train Loss: 0.0009, Val Loss: 0.1236\n",
      "Epoch 3/100, Train Loss: 0.0009, Val Loss: 0.1240\n",
      "Epoch 4/100, Train Loss: 0.0009, Val Loss: 0.1241\n",
      "Epoch 5/100, Train Loss: 0.0009, Val Loss: 0.1242\n",
      "Epoch 6/100, Train Loss: 0.0009, Val Loss: 0.1236\n",
      "Epoch 7/100, Train Loss: 0.0009, Val Loss: 0.1239\n",
      "Epoch 8/100, Train Loss: 0.0009, Val Loss: 0.1241\n",
      "Epoch 9/100, Train Loss: 0.0009, Val Loss: 0.1239\n",
      "Epoch 10/100, Train Loss: 0.0009, Val Loss: 0.1242\n",
      "Epoch 11/100, Train Loss: 0.0009, Val Loss: 0.1237\n",
      "Epoch 12/100, Train Loss: 0.0009, Val Loss: 0.1238\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 30/100 - Train Loss: 0.0008981360701613239 - Val Loss: 0.1237608256207501\n",
      "Epoch 1/100, Train Loss: 0.0009, Val Loss: 0.1238\n",
      "Epoch 2/100, Train Loss: 0.0009, Val Loss: 0.1240\n",
      "Epoch 3/100, Train Loss: 0.0009, Val Loss: 0.1246\n",
      "Epoch 4/100, Train Loss: 0.0009, Val Loss: 0.1239\n",
      "Epoch 5/100, Train Loss: 0.0009, Val Loss: 0.1243\n",
      "Epoch 6/100, Train Loss: 0.0009, Val Loss: 0.1246\n",
      "Epoch 7/100, Train Loss: 0.0009, Val Loss: 0.1242\n",
      "Epoch 8/100, Train Loss: 0.0009, Val Loss: 0.1241\n",
      "Epoch 9/100, Train Loss: 0.0009, Val Loss: 0.1243\n",
      "Epoch 10/100, Train Loss: 0.0009, Val Loss: 0.1240\n",
      "Epoch 11/100, Train Loss: 0.0009, Val Loss: 0.1238\n",
      "Epoch 12/100, Train Loss: 0.0009, Val Loss: 0.1241\n",
      "Epoch 13/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 14/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 15/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 16/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 17/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 18/100, Train Loss: 0.0009, Val Loss: 0.1244\n",
      "Epoch 19/100, Train Loss: 0.0009, Val Loss: 0.1250\n",
      "Epoch 20/100, Train Loss: 0.0008, Val Loss: 0.1247\n",
      "Epoch 21/100, Train Loss: 0.0008, Val Loss: 0.1247\n",
      "Early stopping triggered at epoch 21\n",
      "Epoch 31/100 - Train Loss: 0.0008490521272387877 - Val Loss: 0.12474109109502078\n",
      "Epoch 1/100, Train Loss: 0.0008, Val Loss: 0.1248\n",
      "Epoch 2/100, Train Loss: 0.0008, Val Loss: 0.1248\n",
      "Epoch 3/100, Train Loss: 0.0008, Val Loss: 0.1245\n",
      "Epoch 4/100, Train Loss: 0.0008, Val Loss: 0.1249\n",
      "Epoch 5/100, Train Loss: 0.0008, Val Loss: 0.1247\n",
      "Epoch 6/100, Train Loss: 0.0008, Val Loss: 0.1251\n",
      "Epoch 7/100, Train Loss: 0.0008, Val Loss: 0.1246\n",
      "Epoch 8/100, Train Loss: 0.0008, Val Loss: 0.1248\n",
      "Epoch 9/100, Train Loss: 0.0008, Val Loss: 0.1250\n",
      "Epoch 10/100, Train Loss: 0.0008, Val Loss: 0.1249\n",
      "Epoch 11/100, Train Loss: 0.0008, Val Loss: 0.1250\n",
      "Epoch 12/100, Train Loss: 0.0008, Val Loss: 0.1254\n",
      "Epoch 13/100, Train Loss: 0.0008, Val Loss: 0.1248\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 32/100 - Train Loss: 0.0008171463930130536 - Val Loss: 0.12483477523099656\n",
      "Epoch 1/100, Train Loss: 0.0008, Val Loss: 0.1248\n",
      "Epoch 2/100, Train Loss: 0.0008, Val Loss: 0.1251\n",
      "Epoch 3/100, Train Loss: 0.0008, Val Loss: 0.1253\n",
      "Epoch 4/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 5/100, Train Loss: 0.0008, Val Loss: 0.1255\n",
      "Epoch 6/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 7/100, Train Loss: 0.0008, Val Loss: 0.1255\n",
      "Epoch 8/100, Train Loss: 0.0008, Val Loss: 0.1253\n",
      "Epoch 9/100, Train Loss: 0.0008, Val Loss: 0.1258\n",
      "Epoch 10/100, Train Loss: 0.0008, Val Loss: 0.1251\n",
      "Epoch 11/100, Train Loss: 0.0008, Val Loss: 0.1250\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 33/100 - Train Loss: 0.0008005286917759301 - Val Loss: 0.12503739329147712\n",
      "Epoch 1/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 2/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 3/100, Train Loss: 0.0008, Val Loss: 0.1254\n",
      "Epoch 4/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 5/100, Train Loss: 0.0008, Val Loss: 0.1260\n",
      "Epoch 6/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 7/100, Train Loss: 0.0008, Val Loss: 0.1255\n",
      "Epoch 8/100, Train Loss: 0.0008, Val Loss: 0.1258\n",
      "Epoch 9/100, Train Loss: 0.0008, Val Loss: 0.1254\n",
      "Epoch 10/100, Train Loss: 0.0008, Val Loss: 0.1259\n",
      "Epoch 11/100, Train Loss: 0.0008, Val Loss: 0.1258\n",
      "Epoch 12/100, Train Loss: 0.0008, Val Loss: 0.1257\n",
      "Epoch 13/100, Train Loss: 0.0008, Val Loss: 0.1257\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 34/100 - Train Loss: 0.0007679047762784112 - Val Loss: 0.1256548340986107\n",
      "Epoch 1/100, Train Loss: 0.0008, Val Loss: 0.1261\n",
      "Epoch 2/100, Train Loss: 0.0008, Val Loss: 0.1252\n",
      "Epoch 3/100, Train Loss: 0.0008, Val Loss: 0.1258\n",
      "Epoch 4/100, Train Loss: 0.0008, Val Loss: 0.1254\n",
      "Epoch 5/100, Train Loss: 0.0008, Val Loss: 0.1255\n",
      "Epoch 6/100, Train Loss: 0.0008, Val Loss: 0.1261\n",
      "Epoch 7/100, Train Loss: 0.0008, Val Loss: 0.1257\n",
      "Epoch 8/100, Train Loss: 0.0008, Val Loss: 0.1256\n",
      "Epoch 9/100, Train Loss: 0.0008, Val Loss: 0.1267\n",
      "Epoch 10/100, Train Loss: 0.0007, Val Loss: 0.1261\n",
      "Epoch 11/100, Train Loss: 0.0007, Val Loss: 0.1259\n",
      "Epoch 12/100, Train Loss: 0.0008, Val Loss: 0.1260\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 35/100 - Train Loss: 0.0007504339917796847 - Val Loss: 0.12596181591989478\n",
      "Epoch 1/100, Train Loss: 0.0007, Val Loss: 0.1255\n",
      "Epoch 2/100, Train Loss: 0.0007, Val Loss: 0.1264\n",
      "Epoch 3/100, Train Loss: 0.0007, Val Loss: 0.1264\n",
      "Epoch 4/100, Train Loss: 0.0007, Val Loss: 0.1256\n",
      "Epoch 5/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 6/100, Train Loss: 0.0007, Val Loss: 0.1260\n",
      "Epoch 7/100, Train Loss: 0.0007, Val Loss: 0.1262\n",
      "Epoch 8/100, Train Loss: 0.0007, Val Loss: 0.1260\n",
      "Epoch 9/100, Train Loss: 0.0007, Val Loss: 0.1260\n",
      "Epoch 10/100, Train Loss: 0.0007, Val Loss: 0.1261\n",
      "Epoch 11/100, Train Loss: 0.0007, Val Loss: 0.1260\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 36/100 - Train Loss: 0.0007245934065111854 - Val Loss: 0.1260325778854871\n",
      "Epoch 1/100, Train Loss: 0.0007, Val Loss: 0.1261\n",
      "Epoch 2/100, Train Loss: 0.0007, Val Loss: 0.1263\n",
      "Epoch 3/100, Train Loss: 0.0007, Val Loss: 0.1264\n",
      "Epoch 4/100, Train Loss: 0.0007, Val Loss: 0.1261\n",
      "Epoch 5/100, Train Loss: 0.0007, Val Loss: 0.1258\n",
      "Epoch 6/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 7/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 8/100, Train Loss: 0.0007, Val Loss: 0.1263\n",
      "Epoch 9/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 10/100, Train Loss: 0.0007, Val Loss: 0.1260\n",
      "Epoch 11/100, Train Loss: 0.0007, Val Loss: 0.1262\n",
      "Epoch 12/100, Train Loss: 0.0007, Val Loss: 0.1268\n",
      "Epoch 13/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Epoch 14/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Epoch 15/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 37/100 - Train Loss: 0.0007002443454504993 - Val Loss: 0.12700023145872524\n",
      "Epoch 1/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 2/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Epoch 3/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 4/100, Train Loss: 0.0007, Val Loss: 0.1272\n",
      "Epoch 5/100, Train Loss: 0.0007, Val Loss: 0.1268\n",
      "Epoch 6/100, Train Loss: 0.0007, Val Loss: 0.1267\n",
      "Epoch 7/100, Train Loss: 0.0007, Val Loss: 0.1269\n",
      "Epoch 8/100, Train Loss: 0.0007, Val Loss: 0.1272\n",
      "Epoch 9/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Epoch 10/100, Train Loss: 0.0007, Val Loss: 0.1266\n",
      "Epoch 11/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 38/100 - Train Loss: 0.0006819095021722655 - Val Loss: 0.1270587730187312\n",
      "Epoch 1/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Epoch 2/100, Train Loss: 0.0007, Val Loss: 0.1267\n",
      "Epoch 3/100, Train Loss: 0.0007, Val Loss: 0.1268\n",
      "Epoch 4/100, Train Loss: 0.0007, Val Loss: 0.1272\n",
      "Epoch 5/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Epoch 6/100, Train Loss: 0.0007, Val Loss: 0.1270\n",
      "Epoch 7/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Epoch 8/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Epoch 9/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Epoch 10/100, Train Loss: 0.0007, Val Loss: 0.1274\n",
      "Epoch 11/100, Train Loss: 0.0007, Val Loss: 0.1274\n",
      "Epoch 12/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 39/100 - Train Loss: 0.0006662956392001335 - Val Loss: 0.12732197152616806\n",
      "Epoch 1/100, Train Loss: 0.0007, Val Loss: 0.1272\n",
      "Epoch 2/100, Train Loss: 0.0007, Val Loss: 0.1269\n",
      "Epoch 3/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Epoch 4/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Epoch 5/100, Train Loss: 0.0007, Val Loss: 0.1275\n",
      "Epoch 6/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Epoch 7/100, Train Loss: 0.0007, Val Loss: 0.1271\n",
      "Epoch 8/100, Train Loss: 0.0007, Val Loss: 0.1276\n",
      "Epoch 9/100, Train Loss: 0.0007, Val Loss: 0.1273\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1272\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1276\n",
      "Epoch 12/100, Train Loss: 0.0006, Val Loss: 0.1273\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 40/100 - Train Loss: 0.0006499571210000644 - Val Loss: 0.12732929735121915\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1275\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1274\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1279\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1270\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1274\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1275\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1275\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1276\n",
      "Epoch 12/100, Train Loss: 0.0006, Val Loss: 0.1279\n",
      "Epoch 13/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Epoch 14/100, Train Loss: 0.0006, Val Loss: 0.1278\n",
      "Epoch 15/100, Train Loss: 0.0006, Val Loss: 0.1275\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 41/100 - Train Loss: 0.0006286876444118291 - Val Loss: 0.12749810468988507\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1281\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1279\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1280\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1275\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1280\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1282\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1281\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1278\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1276\n",
      "Epoch 12/100, Train Loss: 0.0006, Val Loss: 0.1281\n",
      "Epoch 13/100, Train Loss: 0.0006, Val Loss: 0.1278\n",
      "Epoch 14/100, Train Loss: 0.0006, Val Loss: 0.1277\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 42/100 - Train Loss: 0.0006107465281704666 - Val Loss: 0.12766840869356338\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1279\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1285\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1283\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1281\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1288\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1282\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1283\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1285\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1283\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 43/100 - Train Loss: 0.0005971808811404772 - Val Loss: 0.12830247536206496\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1285\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1285\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1285\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1282\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1286\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1288\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1286\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 12/100, Train Loss: 0.0006, Val Loss: 0.1281\n",
      "Epoch 13/100, Train Loss: 0.0006, Val Loss: 0.1288\n",
      "Epoch 14/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 15/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 16/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 17/100, Train Loss: 0.0006, Val Loss: 0.1284\n",
      "Epoch 18/100, Train Loss: 0.0006, Val Loss: 0.1286\n",
      "Epoch 19/100, Train Loss: 0.0006, Val Loss: 0.1283\n",
      "Epoch 20/100, Train Loss: 0.0006, Val Loss: 0.1287\n",
      "Epoch 21/100, Train Loss: 0.0006, Val Loss: 0.1286\n",
      "Epoch 22/100, Train Loss: 0.0006, Val Loss: 0.1288\n",
      "Early stopping triggered at epoch 22\n",
      "Epoch 44/100 - Train Loss: 0.0005738372318066331 - Val Loss: 0.12879972517634666\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1286\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1287\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1290\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1291\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1287\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1292\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1291\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 45/100 - Train Loss: 0.000562064023255435 - Val Loss: 0.1291149235053069\n",
      "Epoch 1/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 2/100, Train Loss: 0.0006, Val Loss: 0.1291\n",
      "Epoch 3/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 4/100, Train Loss: 0.0006, Val Loss: 0.1291\n",
      "Epoch 5/100, Train Loss: 0.0006, Val Loss: 0.1292\n",
      "Epoch 6/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 7/100, Train Loss: 0.0006, Val Loss: 0.1293\n",
      "Epoch 8/100, Train Loss: 0.0006, Val Loss: 0.1289\n",
      "Epoch 9/100, Train Loss: 0.0006, Val Loss: 0.1295\n",
      "Epoch 10/100, Train Loss: 0.0006, Val Loss: 0.1291\n",
      "Epoch 11/100, Train Loss: 0.0006, Val Loss: 0.1293\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 13/100, Train Loss: 0.0005, Val Loss: 0.1296\n",
      "Epoch 14/100, Train Loss: 0.0005, Val Loss: 0.1290\n",
      "Epoch 15/100, Train Loss: 0.0005, Val Loss: 0.1290\n",
      "Epoch 16/100, Train Loss: 0.0005, Val Loss: 0.1293\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 46/100 - Train Loss: 0.000546214152891493 - Val Loss: 0.1293496182973618\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1292\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1296\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1291\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1292\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1293\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1293\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1293\n",
      "Epoch 13/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 14/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 15/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 16/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 47/100 - Train Loss: 0.0005301482943756262 - Val Loss: 0.1295221425388166\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1294\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1293\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1298\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1297\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1297\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1299\n",
      "Epoch 13/100, Train Loss: 0.0005, Val Loss: 0.1298\n",
      "Epoch 14/100, Train Loss: 0.0005, Val Loss: 0.1298\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 48/100 - Train Loss: 0.0005173016026100347 - Val Loss: 0.1297994314090959\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1296\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1295\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1299\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1303\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1299\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1302\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1302\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 49/100 - Train Loss: 0.0005085958082892991 - Val Loss: 0.13017936597580426\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1299\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1298\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1298\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1300\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1303\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1302\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1302\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 50/100 - Train Loss: 0.0004986952811789699 - Val Loss: 0.13024731084460892\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1299\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1303\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1302\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1305\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1305\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1306\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1306\n",
      "Early stopping triggered at epoch 11\n",
      "Epoch 51/100 - Train Loss: 0.0004899196610320767 - Val Loss: 0.1305884628270586\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1304\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1303\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1306\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1305\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1304\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1305\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1309\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1306\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1301\n",
      "Epoch 13/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Epoch 14/100, Train Loss: 0.0005, Val Loss: 0.1305\n",
      "Epoch 15/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 16/100, Train Loss: 0.0005, Val Loss: 0.1309\n",
      "Epoch 17/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 18/100, Train Loss: 0.0005, Val Loss: 0.1308\n",
      "Epoch 19/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 20/100, Train Loss: 0.0005, Val Loss: 0.1312\n",
      "Epoch 21/100, Train Loss: 0.0005, Val Loss: 0.1306\n",
      "Epoch 22/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Early stopping triggered at epoch 22\n",
      "Epoch 52/100 - Train Loss: 0.00047362938226601375 - Val Loss: 0.13101156774329412\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1308\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1308\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1309\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1308\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1308\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1313\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Epoch 13/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 14/100, Train Loss: 0.0005, Val Loss: 0.1307\n",
      "Epoch 15/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 53/100 - Train Loss: 0.0004625825980190218 - Val Loss: 0.13100290334622708\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1310\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1309\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1312\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1309\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 8/100, Train Loss: 0.0005, Val Loss: 0.1312\n",
      "Epoch 9/100, Train Loss: 0.0005, Val Loss: 0.1313\n",
      "Epoch 10/100, Train Loss: 0.0005, Val Loss: 0.1311\n",
      "Epoch 11/100, Train Loss: 0.0005, Val Loss: 0.1313\n",
      "Epoch 12/100, Train Loss: 0.0005, Val Loss: 0.1314\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 54/100 - Train Loss: 0.0004548761227513864 - Val Loss: 0.1313783672465671\n",
      "Epoch 1/100, Train Loss: 0.0005, Val Loss: 0.1314\n",
      "Epoch 2/100, Train Loss: 0.0005, Val Loss: 0.1312\n",
      "Epoch 3/100, Train Loss: 0.0005, Val Loss: 0.1315\n",
      "Epoch 4/100, Train Loss: 0.0005, Val Loss: 0.1314\n",
      "Epoch 5/100, Train Loss: 0.0005, Val Loss: 0.1315\n",
      "Epoch 6/100, Train Loss: 0.0005, Val Loss: 0.1314\n",
      "Epoch 7/100, Train Loss: 0.0005, Val Loss: 0.1313\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1310\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1311\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1313\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1312\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1315\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1313\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1313\n",
      "Epoch 17/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 18/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Early stopping triggered at epoch 18\n",
      "Epoch 55/100 - Train Loss: 0.0004424892709446556 - Val Loss: 0.1313637751194428\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1315\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1315\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1313\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1316\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1316\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 56/100 - Train Loss: 0.00043458819955645374 - Val Loss: 0.13185336875021322\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1314\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1317\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1317\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1324\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 57/100 - Train Loss: 0.0004297059444869568 - Val Loss: 0.1323570282552658\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1323\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 58/100 - Train Loss: 0.00042055767910767575 - Val Loss: 0.1318296226578303\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1319\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1320\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1318\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1324\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1324\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1324\n",
      "Epoch 17/100, Train Loss: 0.0004, Val Loss: 0.1323\n",
      "Epoch 18/100, Train Loss: 0.0004, Val Loss: 0.1321\n",
      "Epoch 19/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Early stopping triggered at epoch 19\n",
      "Epoch 59/100 - Train Loss: 0.0004100292227097812 - Val Loss: 0.13222392186239842\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1323\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1322\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1324\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 17/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Early stopping triggered at epoch 17\n",
      "Epoch 60/100 - Train Loss: 0.00040182999945230844 - Val Loss: 0.13267976465765927\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1325\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1326\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1327\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 61/100 - Train Loss: 0.00039284949902443394 - Val Loss: 0.13289377427574978\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1328\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Epoch 17/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 18/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 19/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 20/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 21/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 22/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 23/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 24/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Early stopping triggered at epoch 24\n",
      "Epoch 62/100 - Train Loss: 0.0003815178867697757 - Val Loss: 0.13296359512815742\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1333\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1329\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1330\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1331\n",
      "Early stopping triggered at epoch 12\n",
      "Epoch 63/100 - Train Loss: 0.00037543931972413793 - Val Loss: 0.13314878180404752\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1332\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1333\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Early stopping triggered at epoch 14\n",
      "Epoch 64/100 - Train Loss: 0.00036911930540344787 - Val Loss: 0.13338761309891833\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1333\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Early stopping triggered at epoch 16\n",
      "Epoch 65/100 - Train Loss: 0.0003626074083898065 - Val Loss: 0.13374433490465865\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1334\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1335\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1336\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Early stopping triggered at epoch 13\n",
      "Epoch 66/100 - Train Loss: 0.0003566414034014074 - Val Loss: 0.13383563676281593\n",
      "Epoch 1/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 2/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 3/100, Train Loss: 0.0004, Val Loss: 0.1338\n",
      "Epoch 4/100, Train Loss: 0.0004, Val Loss: 0.1340\n",
      "Epoch 5/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 6/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 7/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 8/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 9/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 10/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 11/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 12/100, Train Loss: 0.0004, Val Loss: 0.1340\n",
      "Epoch 13/100, Train Loss: 0.0004, Val Loss: 0.1341\n",
      "Epoch 14/100, Train Loss: 0.0004, Val Loss: 0.1341\n",
      "Epoch 15/100, Train Loss: 0.0004, Val Loss: 0.1337\n",
      "Epoch 16/100, Train Loss: 0.0004, Val Loss: 0.1339\n",
      "Epoch 17/100, Train Loss: 0.0004, Val Loss: 0.1341\n",
      "Epoch 18/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 19/100, Train Loss: 0.0003, Val Loss: 0.1341\n",
      "Epoch 20/100, Train Loss: 0.0003, Val Loss: 0.1340\n",
      "Epoch 21/100, Train Loss: 0.0003, Val Loss: 0.1338\n",
      "Epoch 22/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 23/100, Train Loss: 0.0003, Val Loss: 0.1340\n",
      "Epoch 24/100, Train Loss: 0.0003, Val Loss: 0.1341\n",
      "Epoch 25/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Early stopping triggered at epoch 25\n",
      "Epoch 67/100 - Train Loss: 0.0003465235495514446 - Val Loss: 0.13431241405282102\n",
      "Epoch 1/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 2/100, Train Loss: 0.0003, Val Loss: 0.1340\n",
      "Epoch 3/100, Train Loss: 0.0003, Val Loss: 0.1341\n",
      "Epoch 4/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 5/100, Train Loss: 0.0003, Val Loss: 0.1341\n",
      "Epoch 6/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 7/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 8/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 9/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 10/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 11/100, Train Loss: 0.0003, Val Loss: 0.1341\n",
      "Epoch 12/100, Train Loss: 0.0003, Val Loss: 0.1340\n",
      "Epoch 13/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 14/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 15/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Epoch 16/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 17/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 18/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 19/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 20/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 21/100, Train Loss: 0.0003, Val Loss: 0.1343\n",
      "Epoch 22/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Early stopping triggered at epoch 22\n",
      "Epoch 68/100 - Train Loss: 0.00033783776341206025 - Val Loss: 0.13435093854409114\n",
      "Epoch 1/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 2/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Epoch 3/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 4/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 5/100, Train Loss: 0.0003, Val Loss: 0.1342\n",
      "Epoch 6/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Epoch 7/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Epoch 8/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 9/100, Train Loss: 0.0003, Val Loss: 0.1344\n",
      "Epoch 10/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 11/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 12/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 13/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 14/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 15/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Early stopping triggered at epoch 15\n",
      "Epoch 69/100 - Train Loss: 0.00033201852696412604 - Val Loss: 0.13460045685336783\n",
      "Epoch 1/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 2/100, Train Loss: 0.0003, Val Loss: 0.1348\n",
      "Epoch 3/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 4/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 5/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 6/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 7/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 8/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 9/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 10/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 11/100, Train Loss: 0.0003, Val Loss: 0.1345\n",
      "Epoch 12/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 13/100, Train Loss: 0.0003, Val Loss: 0.1349\n",
      "Epoch 14/100, Train Loss: 0.0003, Val Loss: 0.1348\n",
      "Epoch 15/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 16/100, Train Loss: 0.0003, Val Loss: 0.1346\n",
      "Epoch 17/100, Train Loss: 0.0003, Val Loss: 0.1349\n",
      "Epoch 18/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 19/100, Train Loss: 0.0003, Val Loss: 0.1348\n",
      "Epoch 20/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 21/100, Train Loss: 0.0003, Val Loss: 0.1350\n",
      "Early stopping triggered at epoch 21\n",
      "Epoch 70/100 - Train Loss: 0.00032472121580628564 - Val Loss: 0.13503614813634282\n",
      "Epoch 1/100, Train Loss: 0.0003, Val Loss: 0.1347\n",
      "Epoch 2/100, Train Loss: 0.0003, Val Loss: 0.1348\n",
      "Epoch 3/100, Train Loss: 0.0003, Val Loss: 0.1349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration dictionary\n",
    "configurations = {\n",
    "    \"num_layers\": 5,\n",
    "    \"layer_sizes\": [784, 256, 128, 64, 10],\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"activation_functions\": [\"sigmoid\", \"tanh\", \"relu\", \"leaky_relu\"],\n",
    "    \"weight_initializations\": [\"zero_init\", \"random_init\", \"normal_init\"]\n",
    "}\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X.reshape(-1, 784) / 255.0\n",
    "X_test = X_test.reshape(-1, 784) / 255.0\n",
    "Y = np.eye(10)[y]\n",
    "Y_test = np.eye(10)[y_test]\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Store training and validation losses for plotting\n",
    "training_losses = {}\n",
    "validation_losses = {}\n",
    "\n",
    "for activation in configurations[\"activation_functions\"]:\n",
    "    for weight_init in configurations[\"weight_initializations\"]:\n",
    "        \n",
    "        print(f\"Training with activation: {activation} and weight initialization: {weight_init}\")\n",
    "        \n",
    "        model = NeuralNetwork(\n",
    "            N=configurations[\"num_layers\"],\n",
    "            layer_sizes=configurations[\"layer_sizes\"],\n",
    "            lr=configurations[\"learning_rate\"],\n",
    "            activation=activation,\n",
    "            weight_init=weight_init,\n",
    "            epochs=configurations[\"epochs\"],\n",
    "            batch_size=configurations[\"batch_size\"]\n",
    "        )\n",
    "\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        \n",
    "        for epoch in range(configurations[\"epochs\"]):\n",
    "            # Training the model with early stopping enabled\n",
    "            train_loss = model.fit(X_train, Y_train, X_val=X_val, Y_val=Y_val, early_stopping=True, patience=10)\n",
    "            val_predictions = model.predict_proba(X_val)\n",
    "            val_loss = -np.mean(np.sum(Y_val * np.log(val_predictions + 1e-8), axis=1)) if val_predictions is not None else None\n",
    "            \n",
    "            # Append losses to history lists\n",
    "            train_loss_history.append(train_loss)\n",
    "            val_loss_history.append(val_loss)\n",
    "            \n",
    "            # Print epoch progress with conditional handling of None values\n",
    "            print(f\"Epoch {epoch + 1}/{configurations['epochs']} - Train Loss: {train_loss if train_loss is not None else 'N/A'} - Val Loss: {val_loss if val_loss is not None else 'N/A'}\")\n",
    "        \n",
    "        training_losses[(activation, weight_init)] = train_loss_history\n",
    "        validation_losses[(activation, weight_init)] = val_loss_history\n",
    "        \n",
    "        model_filename = f\"model_{activation}_{weight_init}.pkl\"\n",
    "        with open(model_filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "# Plot training and validation loss for each configuration\n",
    "for (activation, weight_init), train_loss_history in training_losses.items():\n",
    "    val_loss_history = validation_losses[(activation, weight_init)]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "    plt.title(f\"Activation: {activation}, Weight Init: {weight_init}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
